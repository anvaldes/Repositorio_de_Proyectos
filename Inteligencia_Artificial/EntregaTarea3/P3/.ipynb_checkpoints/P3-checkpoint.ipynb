{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Pregunta \\ \\ 3 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a) $ Investigando sobre boosting llegamos a que boosting es una manera de ensamblar varios modelos debiles de modo que el ensamble sea un modelo de clasificación fuerte. En base a esto, llegamos al siguiente algoritmo presentado en 1996 que consiste en lo siguiente:\n",
    "\n",
    "$  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean los datos $x_1, ..., x_n$ que pueden ser clasificados como $ -1 $ o como $ + 1 $. Definimos $ w_1(i) = \\frac{1}{n} \\ \\ \\forall i \\in \\lbrace 1,..., n \\rbrace $\n",
    "\n",
    "Para $ t = 1,..., T: $\n",
    "\n",
    "1. Mulplicamos a los datos $x_1,...,x_n $ por $ w_t(i) $ para cada $ i $ respectivamente. \\\\\n",
    "\n",
    "2. Realizar un ajuste logistico $ f_t $.\n",
    "\n",
    "3. Sea define $ \\epsilon_t = \\sum_{i=1}^{n} w_{t}(i) \\mathbb{1}  \\lbrace y_i \\neq f_t(x_i) \\rbrace $ donde $ \\mathbb{1}  \\lbrace y_i \\neq f_t(x_i) \\rbrace $ es $0$ si $ y_i = f_t(x_i) $ y vale $1$ si $ y_i \\neq f_t(x_i) $\n",
    "\n",
    "Para este paso también definimos $ \\alpha_t = \\frac{1}{2} ln \\left( \\frac{1-\\epsilon_t}{\\epsilon_t} \\right) $\n",
    "\n",
    "4. Se actualizan los valores de $ w_{t+1}(i) = w_{t}(i) \\cdot e^{-\\alpha_t y_i f_t(x_i)} $ y luego se normalizan estos coeficientes de modo que sumen 1. \n",
    "\n",
    "Luego de terminar el loop se define el clasificador boosting como:\n",
    "\n",
    "$ f_{boost}(x) = sign \\left( \\sum_{t=1}^{T} \\alpha_t f_t(x) \\right) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $\n",
    "\n",
    "Como se observa, la idea que esta detrás de este algoritmo es que se ponderan con más peso los datos que fueron mal clasificados.\n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b)$ Ahora implementamos random forest y este algoritmo para las bases de datos que nos dieron, de donde las bases desde el 2014 al 2017 son de entrenamiento y la del 2017 es de testeo. Y luego de eso, se realizará una comparación con la implementación de regresiones logisticas con coeficientes polinomiales. \n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producto_punto(x_1, x_2):\n",
    "    suma = 0\n",
    "    for i in range(len(x_1)):\n",
    "        suma = suma + x_1[i]*x_2[i]\n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_h(theta, x):\n",
    "    valor = producto_punto(theta, x)\n",
    "    c = 700\n",
    "    if valor >= c:\n",
    "        return 1\n",
    "    elif valor <= -c:\n",
    "        return 0\n",
    "    else:\n",
    "        resultado = 1/(1 + math.exp(-valor))\n",
    "        return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sean vectores en R^n y m muestras    [[y_1, x^(1)], ..., [y_m, x^(m)]]\n",
    "# theta es un vector de R^n\n",
    "\n",
    "def una_iteracion(theta, datos):\n",
    "    nuevo_theta = []\n",
    "    for k in range(len(theta)):\n",
    "        suma = 0\n",
    "        for i in range(len(datos)):\n",
    "            suma = suma + (datos[i][0] - funcion_h(theta, datos[i][1]))*datos[i][1][k]\n",
    "        suma = suma + theta[k]\n",
    "        nuevo_theta.append(suma)\n",
    "    return nuevo_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_regresion_logistica(theta_inicial, datos, T):\n",
    "    theta = theta_inicial\n",
    "    for t in range(T):\n",
    "        theta = una_iteracion(theta, datos)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformacion_punto(punto, d):\n",
    "    lista = []\n",
    "    lista.append(1)\n",
    "    for i in range(d):\n",
    "        lista.append(punto[0]**(i+1))\n",
    "    lista.append(punto[1])\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_regresion_logistica(d, T):\n",
    "    \n",
    "    datos_entrenamiento = []\n",
    "    \n",
    "    for k1 in puntos_positivos_entrenamiento:\n",
    "        datos_entrenamiento.append([1, transformacion_punto(k1, d)])\n",
    "\n",
    "    for k2 in puntos_negativos_entrenamiento:\n",
    "        datos_entrenamiento.append([-1, transformacion_punto(k2, d)])\n",
    "        \n",
    "    theta_0 = []\n",
    "           \n",
    "    for p in range(d+2):\n",
    "        theta_0.append(p)\n",
    "\n",
    "    resultado = calcular_regresion_logistica(theta_0, datos_entrenamiento, T)\n",
    "    \n",
    "    lista_coeficientes = []\n",
    "\n",
    "    for i in range(d+1):\n",
    "        lista_coeficientes.append(-resultado[i]/resultado[d+1])\n",
    "    \n",
    "    eje_x = []\n",
    "    eje_y = []\n",
    "\n",
    "    for i in range(100):\n",
    "        eje_x.append(-2+i*0.04)\n",
    "\n",
    "    for j in eje_x:\n",
    "        suma = 0\n",
    "        for k in range(len(lista_coeficientes)):\n",
    "            suma = suma + lista_coeficientes[k]*(j**k)\n",
    "        eje_y.append(suma)\n",
    "        \n",
    "    return [eje_x, eje_y, resultado, datos_entrenamiento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_error(resultado, datos):\n",
    "\n",
    "    suma = 0\n",
    "    contador = 0\n",
    "\n",
    "    for k in datos:\n",
    "        if (producto_punto(k[1], resultado) >= 0 and k[0] == 1) or (producto_punto(k[1], resultado) <= 0 and k[0] == -1):\n",
    "            suma = suma + 1\n",
    "        contador = contador + 1\n",
    "    \n",
    "    porcentaje = 100*(suma/contador)\n",
    "    return porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sean vectores en R^n y m muestras    [[y_1, x^(1)], ..., [y_m, x^(m)]]\n",
    "# calcular_regresion_logistica(theta_inicial, datos, T)\n",
    "\n",
    "def crear_datos(base):\n",
    "    nuevo_data = []\n",
    "    for i in range(len(base[0])):\n",
    "        lista = []\n",
    "        if base[len(base)-1][i] == 1:\n",
    "            lista.append(1)\n",
    "        else:\n",
    "            lista.append(-1)\n",
    "        new_list = []\n",
    "        for j in range(len(base)-1):\n",
    "            new_list.append(base[j][i])\n",
    "        new_list.append(1)\n",
    "        lista.append(new_list)\n",
    "        nuevo_data.append(lista)\n",
    "    return nuevo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_rango(lista, rango):\n",
    "    nueva_lista = []\n",
    "    for i in lista:\n",
    "        nueva_lista.append(i[rango: rango + 1000])\n",
    "    return nueva_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creacion_datos_testeo(d):\n",
    "\n",
    "    datos_testeo= []\n",
    "\n",
    "    for k1 in puntos_positivos_testeo:\n",
    "        datos_testeo.append([1, transformacion_punto(k1, d)])\n",
    "\n",
    "    for k2 in puntos_negativos_testeo:\n",
    "        datos_testeo.append([-1, transformacion_punto(k2, d)])\n",
    "    \n",
    "    return datos_testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(numero_atributos):\n",
    "    \n",
    "    archivo_2014 = pd.read_csv(\"2014_Financial_Data.csv\")\n",
    "    archivo_2015 = pd.read_csv(\"2015_Financial_Data.csv\")\n",
    "    archivo_2016 = pd.read_csv(\"2016_Financial_Data.csv\")\n",
    "    archivo_2017 = pd.read_csv(\"2017_Financial_Data.csv\")\n",
    "    archivo_2018 = pd.read_csv(\"2018_Financial_Data.csv\")\n",
    "\n",
    "    lista_atributos = []\n",
    "\n",
    "    for i in range(numero_atributos):\n",
    "        lista_atributos.append(random.randint(0, 221))\n",
    "        \n",
    "    nombres = []\n",
    "\n",
    "    for k in archivo_2014:\n",
    "        nombres.append(k)\n",
    "    \n",
    "    nombres.remove(nombres[len(nombres)-2])\n",
    "    nombres.remove(nombres[0])\n",
    "    \n",
    "    nuevos_nombres = []\n",
    "\n",
    "    for i in range(len(lista_atributos)):\n",
    "        nuevos_nombres.append(nombres[lista_atributos[i]])\n",
    "    \n",
    "    nuevo_archivo_2014 = archivo_2014.dropna(subset=nuevos_nombres)\n",
    "    nuevo_archivo_2015 = archivo_2015.dropna(subset=nuevos_nombres)\n",
    "    nuevo_archivo_2016 = archivo_2016.dropna(subset=nuevos_nombres)\n",
    "    nuevo_archivo_2017 = archivo_2017.dropna(subset=nuevos_nombres)\n",
    "    nuevo_archivo_2018 = archivo_2018.dropna(subset=nuevos_nombres)\n",
    "    \n",
    "    nombres = nuevos_nombres\n",
    "    \n",
    "    total_2014 = []\n",
    "\n",
    "    for k in nombres:\n",
    "        columna = []\n",
    "        for j in nuevo_archivo_2014[k]:\n",
    "            columna.append(j)\n",
    "        total_2014.append(columna)\n",
    "\n",
    "    clase_2014 = []\n",
    "    for i in nuevo_archivo_2014['Class']:\n",
    "        clase_2014.append(i)\n",
    "\n",
    "    total_2014.append(clase_2014)\n",
    "\n",
    "    #-----------------------------------------\n",
    "\n",
    "    total_2015 = []\n",
    "\n",
    "    for k in nombres:\n",
    "        columna = []\n",
    "        for j in nuevo_archivo_2015[k]:\n",
    "            columna.append(j)\n",
    "        total_2015.append(columna)\n",
    "\n",
    "    clase_2015 = []\n",
    "    for i in nuevo_archivo_2015['Class']:\n",
    "        clase_2015.append(i)\n",
    "\n",
    "    total_2015.append(clase_2015)\n",
    "\n",
    "    #-----------------------------------------\n",
    "\n",
    "    total_2016 = []\n",
    "\n",
    "    for k in nombres:\n",
    "        columna = []\n",
    "        for j in nuevo_archivo_2016[k]:\n",
    "            columna.append(j)\n",
    "        total_2016.append(columna)\n",
    "\n",
    "    clase_2016 = []\n",
    "    for i in nuevo_archivo_2016['Class']:\n",
    "        clase_2016.append(i)\n",
    "\n",
    "    total_2016.append(clase_2016)\n",
    "\n",
    "    #-----------------------------------------\n",
    "\n",
    "    total_2017 = []\n",
    "\n",
    "    for k in nombres:\n",
    "        columna = []\n",
    "        for j in nuevo_archivo_2017[k]:\n",
    "            columna.append(j)\n",
    "        total_2017.append(columna)\n",
    "\n",
    "    clase_2017 = []\n",
    "    for i in nuevo_archivo_2017['Class']:\n",
    "        clase_2017.append(i)\n",
    "\n",
    "    total_2017.append(clase_2017)\n",
    "\n",
    "    #-----------------------------------------\n",
    "\n",
    "    total_2018 = []\n",
    "\n",
    "    for k in nombres:\n",
    "        columna = []\n",
    "        for j in nuevo_archivo_2018[k]:\n",
    "            columna.append(j)\n",
    "        total_2018.append(columna)\n",
    "\n",
    "    clase_2018 = []\n",
    "    for i in nuevo_archivo_2018['Class']:\n",
    "        clase_2018.append(i)\n",
    "\n",
    "    total_2018.append(clase_2018)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    \n",
    "    diccionario_eleccion = {1: total_2014, 2: total_2015, 3: total_2016, 4: total_2017}\n",
    "\n",
    "    numero_iteraciones = 10\n",
    "\n",
    "    bases = []\n",
    "\n",
    "    for k in range(numero_iteraciones):\n",
    "        year = random.randint(1, 4)\n",
    "        rango = random.randint(0, 500)\n",
    "        base = sacar_rango(diccionario_eleccion[year], rango)\n",
    "        bases.append(base)    \n",
    "    \n",
    "    # Aplicacion de Random Forest\n",
    "\n",
    "    thetas_r_f = []\n",
    "    T = 100\n",
    "\n",
    "    for k in range(numero_iteraciones):\n",
    "        datos_input = crear_datos(bases[k]) \n",
    "        theta_inicial = []\n",
    "        for i in range(len(bases[k])):\n",
    "            theta_inicial.append(0.5)\n",
    "        theta_output = calcular_regresion_logistica(theta_inicial, datos_input, T)\n",
    "        thetas_r_f.append(theta_output)\n",
    "    \n",
    "    theta_r_f_def = []\n",
    "\n",
    "    for i in range(len(thetas_r_f[0])):\n",
    "        theta_r_f_def.append(0)\n",
    "\n",
    "    for j in range(len(thetas_r_f[0])):\n",
    "        for i in range(len(thetas_r_f)):\n",
    "            theta_r_f_def[j] = theta_r_f_def[j] + thetas_r_f[i][j]\n",
    "        theta_r_f_def[j] = theta_r_f_def[j]/len(thetas_r_f)\n",
    "    \n",
    "    datos_input = crear_datos(total_2018)\n",
    "    theta_output = theta_r_f_def\n",
    "    \n",
    "    contador = 0\n",
    "    correcto = 0\n",
    "\n",
    "    for i in range(len(datos_input)):\n",
    "        contador = contador + 1\n",
    "        if np.sign(-producto_punto(datos_input[i][1], theta_output)) == datos_input[i][0]:\n",
    "            correcto = correcto + 1\n",
    "    \n",
    "    return 100*(correcto/contador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_regresion_polinomial(numero_atributo, d, T):\n",
    "    \n",
    "    archivo_2014 = pd.read_csv(\"2014_Financial_Data.csv\")\n",
    "    archivo_2015 = pd.read_csv(\"2015_Financial_Data.csv\")\n",
    "    archivo_2016 = pd.read_csv(\"2016_Financial_Data.csv\")\n",
    "    archivo_2017 = pd.read_csv(\"2017_Financial_Data.csv\")\n",
    "    archivo_2018 = pd.read_csv(\"2018_Financial_Data.csv\")\n",
    "    \n",
    "    nombres = []\n",
    "\n",
    "    for k in archivo_2014:\n",
    "        nombres.append(k)\n",
    "    \n",
    "    nombres.remove(nombres[len(nombres)-2])\n",
    "    nombres.remove(nombres[0])\n",
    "\n",
    "    nuevo_nombre = [nombres[numero_atributo]]  # Desde el 0 hasta el 221\n",
    "    \n",
    "    # Eliminar los datos NAN\n",
    "    \n",
    "    nuevo_archivo_2014 = archivo_2014.dropna(subset=nuevo_nombre)\n",
    "    nuevo_archivo_2015 = archivo_2015.dropna(subset=nuevo_nombre)\n",
    "    nuevo_archivo_2016 = archivo_2016.dropna(subset=nuevo_nombre)\n",
    "    nuevo_archivo_2017 = archivo_2017.dropna(subset=nuevo_nombre)\n",
    "    nuevo_archivo_2018 = archivo_2018.dropna(subset=nuevo_nombre)\n",
    "    \n",
    "    data_final_2014 = calcular_base_datos(nuevo_archivo_2014, nuevo_nombre, d)\n",
    "    data_final_2015 = calcular_base_datos(nuevo_archivo_2015, nuevo_nombre, d)\n",
    "    data_final_2016 = calcular_base_datos(nuevo_archivo_2016, nuevo_nombre, d)\n",
    "    data_final_2017 = calcular_base_datos(nuevo_archivo_2017, nuevo_nombre, d)\n",
    "    data_final_2018 = calcular_base_datos(nuevo_archivo_2018, nuevo_nombre, d)\n",
    "    \n",
    "    data_entrenamiento = []\n",
    "\n",
    "    for k in range(len(data_final_2014)):\n",
    "        data_entrenamiento.append(data_final_2014[k])\n",
    "\n",
    "    for k in range(len(data_final_2015)):\n",
    "        data_entrenamiento.append(data_final_2015[k])\n",
    "\n",
    "    for k in range(len(data_final_2016)):\n",
    "        data_entrenamiento.append(data_final_2016[k])\n",
    "\n",
    "    for k in range(len(data_final_2017)):\n",
    "        data_entrenamiento.append(data_final_2017[k])\n",
    "\n",
    "    data_testeo = data_final_2018\n",
    "    \n",
    "    nuevo_theta = []\n",
    "    for i in range(d+1):\n",
    "        nuevo_theta.append(0.5)\n",
    "\n",
    "    output = calcular_regresion_logistica(nuevo_theta, data_entrenamiento, T)\n",
    "    \n",
    "    contador = 0\n",
    "    correcto = 0\n",
    "\n",
    "    for i in data_entrenamiento:\n",
    "        if np.sign(producto_punto(i[1], output)) == i[0]:\n",
    "            correcto = correcto + 1\n",
    "        contador = contador + 1\n",
    "    \n",
    "    precision_entrenamiento = 100*(correcto/contador)\n",
    "    \n",
    "    \n",
    "    contador = 0\n",
    "    correcto = 0\n",
    "\n",
    "    for i in data_testeo:\n",
    "        if np.sign(producto_punto(i[1], output)) == i[0]:\n",
    "            correcto = correcto + 1\n",
    "        contador = contador + 1\n",
    "\n",
    "    precision_testeo = 100*(correcto/contador)\n",
    "    \n",
    "    return [precision_entrenamiento, precision_testeo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_base_datos(nuevo_archivo, nuevo_nombre, d):  #NUEVO NOMBRE ES DEL TIPO [[nuevo_nombre]]\n",
    "    lista = []\n",
    "    for i in nuevo_archivo[nuevo_nombre[0]]:\n",
    "        lista.append(i)\n",
    "    \n",
    "    clase = []\n",
    "    for j in nuevo_archivo['Class']:\n",
    "        clase.append(int(2*j-1))\n",
    "    \n",
    "    nueva_data = []\n",
    "    \n",
    "    for k in range(len(lista)):\n",
    "        \n",
    "        vector = []\n",
    "        \n",
    "        for h in range(d+1):\n",
    "            vector.append(lista[k]**h)\n",
    "        \n",
    "        vector_ext = [clase[k], vector]\n",
    "        \n",
    "        nueva_data.append(vector_ext)\n",
    "    \n",
    "    return nueva_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicar_data(data, w):  #data y w tienen que tener el mismo largo\n",
    "    nueva_data = []\n",
    "    for i in range(len(data)):\n",
    "        data[i][0] # esto tiene que seguir igual\n",
    "        new_list = []\n",
    "        for j in range(len(data[i][1])):\n",
    "            new_list.append(data[i][1][j]*w[i])\n",
    "        nueva_data.append([data[i][0], new_list])\n",
    "    return nueva_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $\n",
    "\n",
    "$ Random \\ Forest $ \n",
    "\n",
    "$ $ \n",
    "\n",
    "Aquí realizamos la implementación de random forest (la parte de seleccionar aleatoriamente los atributos y que elementos de los atributos se hace en la definición de la función de random forest). Como se observa hicimos un analisis de como era el rendimiento (en el testeo) de este algoritmo en función del número de atributos que este poseia y llegamos a que el optimo era cuando son $ 4 $ atributos obteniendo una precisión del 78.34 %.\n",
    "\n",
    "$ $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración:  1\n",
      "Tiempo:  5.338791608810425\n",
      "Iteración:  2\n",
      "Tiempo:  7.182851314544678\n",
      "Iteración:  3\n",
      "Tiempo:  9.891092538833618\n",
      "Iteración:  4\n",
      "Tiempo:  13.249605894088745\n",
      "Iteración:  5\n",
      "Tiempo:  16.082818508148193\n"
     ]
    }
   ],
   "source": [
    "N = 11\n",
    "precisiones = []\n",
    "eje_n = []\n",
    "\n",
    "for n in range(1, N+1):\n",
    "    start = time.time()\n",
    "    precision = random_forest(n)\n",
    "    precisiones.append(precision)\n",
    "    eje_n.append(n)\n",
    "    end = time.time()\n",
    "    print(\"Iteración: \", n)\n",
    "    print(\"Tiempo: \", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eje_n, precisiones)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(precisiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $\n",
    "\n",
    "$ Regresion \\ Logística \\ Polinomial $\n",
    "\n",
    "$ $\n",
    "\n",
    "Aca lo que hicimos fue calcular regresiones logisticas polinomiales hasta de grado $10$. Luego realizamos estos para todos los atributos y así llegamos a que el que mejor resultados tenía era el 9 y es por esto que utilizamos este atributo en la siguiente parte y mostramos el rendimiento en función del grado de polinomio. Como se observa, cuando el grado es 2 se obtiene el máximo con una precisión de 69.15 %.\n",
    "\n",
    "$ $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10\n",
    "T = 100\n",
    "\n",
    "eje_d = []\n",
    "resultados_testeo = []\n",
    "\n",
    "for d in range(1, D+1):\n",
    "    start = time.time()\n",
    "    output = calcular_regresion_polinomial(9, d, T)\n",
    "    end = time.time()\n",
    "    print(\"Iteración: \", d)\n",
    "    print(\"Tiempo: \", end-start)\n",
    "    resultados_testeo.append(output[1])\n",
    "    eje_d.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eje_d, resultados_testeo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_max = resultados_testeo.index(max(resultados_testeo))\n",
    "print(eje_d[indice_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(resultados_testeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $\n",
    "\n",
    "$ Boosting $\n",
    "\n",
    "Aquí comienza la implementación de boosting en donde realizamos 10 iteraciones y obtuvimos una precisión de 68.1 %. \n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_2014 = pd.read_csv(\"2014_Financial_Data.csv\")\n",
    "archivo_2015 = pd.read_csv(\"2015_Financial_Data.csv\")\n",
    "archivo_2016 = pd.read_csv(\"2016_Financial_Data.csv\")\n",
    "archivo_2017 = pd.read_csv(\"2017_Financial_Data.csv\")\n",
    "archivo_2018 = pd.read_csv(\"2018_Financial_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = []\n",
    "\n",
    "for k in archivo_2014:\n",
    "        nombres.append(k)\n",
    "    \n",
    "nombres.remove(nombres[len(nombres)-2])\n",
    "nombres.remove(nombres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = nombres[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres.append('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los datos NAN\n",
    "    \n",
    "nuevo_archivo_2014 = archivo_2014.dropna(subset=nombres)\n",
    "nuevo_archivo_2015 = archivo_2015.dropna(subset=nombres)\n",
    "nuevo_archivo_2016 = archivo_2016.dropna(subset=nombres)\n",
    "nuevo_archivo_2017 = archivo_2017.dropna(subset=nombres)\n",
    "nuevo_archivo_2018 = archivo_2018.dropna(subset=nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_data_2014 = []\n",
    "\n",
    "for k in nombres:\n",
    "    lista = []\n",
    "    for j in nuevo_archivo_2014[k]:\n",
    "        lista.append(j)\n",
    "    nueva_data_2014.append(lista)\n",
    "\n",
    "nueva_data_2015 = []\n",
    "\n",
    "for k in nombres:\n",
    "    lista = []\n",
    "    for j in nuevo_archivo_2015[k]:\n",
    "        lista.append(j)\n",
    "    nueva_data_2015.append(lista)\n",
    "\n",
    "nueva_data_2016 = []\n",
    "\n",
    "for k in nombres:\n",
    "    lista = []\n",
    "    for j in nuevo_archivo_2016[k]:\n",
    "        lista.append(j)\n",
    "    nueva_data_2016.append(lista)\n",
    "\n",
    "nueva_data_2017 = []\n",
    "\n",
    "for k in nombres:\n",
    "    lista = []\n",
    "    for j in nuevo_archivo_2017[k]:\n",
    "        lista.append(j)\n",
    "    nueva_data_2017.append(lista)\n",
    "\n",
    "nueva_data_2018 = []\n",
    "\n",
    "for k in nombres:\n",
    "    lista = []\n",
    "    for j in nuevo_archivo_2018[k]:\n",
    "        lista.append(j)\n",
    "    nueva_data_2018.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de la data de entrenamiento\n",
    "\n",
    "data_entrenamiento = []\n",
    "\n",
    "for k in range(len(nueva_data_2014[0])):\n",
    "    lista = []\n",
    "    for j in range(10):\n",
    "        lista.append(nueva_data_2014[j][k])\n",
    "    lista.append(1)\n",
    "    \n",
    "    data_entrenamiento.append([int(2*nueva_data_2014[10][k]-1), lista])\n",
    "\n",
    "for k in range(len(nueva_data_2015[0])):\n",
    "    lista = []\n",
    "    for j in range(10):\n",
    "        lista.append(nueva_data_2015[j][k])\n",
    "    lista.append(1)\n",
    "    \n",
    "    data_entrenamiento.append([int(2*nueva_data_2015[10][k]-1), lista])\n",
    "\n",
    "for k in range(len(nueva_data_2016[0])):\n",
    "    lista = []\n",
    "    for j in range(10):\n",
    "        lista.append(nueva_data_2016[j][k])\n",
    "    lista.append(1)\n",
    "    \n",
    "    data_entrenamiento.append([int(2*nueva_data_2016[10][k]-1), lista])\n",
    "\n",
    "for k in range(len(nueva_data_2017[0])):\n",
    "    lista = []\n",
    "    for j in range(10):\n",
    "        lista.append(nueva_data_2017[j][k])\n",
    "    lista.append(1)\n",
    "    \n",
    "    data_entrenamiento.append([int(2*nueva_data_2017[10][k]-1), lista])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_testeo = []\n",
    "\n",
    "for k in range(len(nueva_data_2018[0])):\n",
    "    lista = []\n",
    "    for j in range(10):\n",
    "        lista.append(nueva_data_2018[j][k])\n",
    "    lista.append(1)\n",
    "    \n",
    "    data_testeo.append([int(2*nueva_data_2018[10][k]-1), lista])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------ INICIALIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "for j in range(len(data_entrenamiento)):\n",
    "    w.append(1/len(data_entrenamiento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = multiplicar_data(data_entrenamiento, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_inicial = []\n",
    "\n",
    "for j in range(11):\n",
    "    theta_inicial.append(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteraciones = 10\n",
    "T = 100\n",
    "coeficientes_iter = []\n",
    "alphas = []\n",
    "\n",
    "for t in range(iteraciones):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #CALCULO DE LOS COEFICIENTES\n",
    "    coeficientes = calcular_regresion_logistica(theta_inicial, data, T)\n",
    "    coeficientes_iter.append(coeficientes)\n",
    "    \n",
    "    #CALCULO DE LAS PREDICCIONES\n",
    "    predicciones = []\n",
    "    for i in data:\n",
    "        predicciones.append(np.sign(producto_punto(i[1], coeficientes)))\n",
    "    \n",
    "    #COMPARACIONES\n",
    "    comparaciones = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i][0] == predicciones[i]:\n",
    "            comparaciones.append(0)\n",
    "        else:\n",
    "            comparaciones.append(1)\n",
    "    \n",
    "    #CALCULO DEL EPSILON_t y ALPHA_t\n",
    "    epsilon = producto_punto(comparaciones, w)\n",
    "    \n",
    "    alpha = (1/2)*math.log((1-epsilon)/epsilon)\n",
    "    alphas.append(alpha)\n",
    "    \n",
    "    #CALCULAR NUEVAMENTE LOS W\n",
    "    \n",
    "    for k in range(len(w)):\n",
    "        w[k] = w[k]*math.exp(-alpha*(-2*comparaciones[k] + 1))\n",
    "    \n",
    "    promedio = np.mean(w)*len(w)\n",
    "    \n",
    "    for h in range(len(w)):\n",
    "        w[h] = w[h]/promedio\n",
    "    \n",
    "    data = multiplicar_data(data, w)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Iteración: \", t)\n",
    "    print(\"Tiempo: \", end-start)\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coeficientes_iter\n",
    "#alphas\n",
    "\n",
    "nuevos_coeficientes = []\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    new_coef = []\n",
    "    for j in range(len(coeficientes_iter[i])):\n",
    "        new_coef.append(coeficientes_iter[i][j]*alphas[i])\n",
    "    nuevos_coeficientes.append(new_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeficientes_definitivos = []\n",
    "\n",
    "for i in range(len(nuevos_coeficientes)):\n",
    "    if i == 0:\n",
    "        coeficientes_definitivos.append(nuevos_coeficientes[0])\n",
    "    else:\n",
    "        nuevo_elemento = []\n",
    "        for j in range(len(nuevos_coeficientes[i])):\n",
    "            nuevo_elemento.append(nuevos_coeficientes[i][j] + coeficientes_definitivos[i-1][j])\n",
    "        coeficientes_definitivos.append(nuevo_elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_entrenamiento = []\n",
    "eje_n = []\n",
    "\n",
    "for i in range(len(coeficientes_definitivos)):\n",
    "    coeficientes_definitivos[i]\n",
    "    \n",
    "    contador = 0\n",
    "    correcto = 0\n",
    "    \n",
    "    for j in data_entrenamiento:\n",
    "        if np.sign(producto_punto(j[1], coeficientes_definitivos[i])) == j[0]:\n",
    "            correcto = correcto + 1\n",
    "        contador = contador + 1\n",
    "    \n",
    "    precision_entrenamiento.append((correcto/contador)*100)\n",
    "    eje_n.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_testeo = []\n",
    "eje_n = []\n",
    "\n",
    "for i in range(len(coeficientes_definitivos)):\n",
    "    coeficientes_definitivos[i]\n",
    "    \n",
    "    contador = 0\n",
    "    correcto = 0\n",
    "    \n",
    "    for j in data_testeo:\n",
    "        if np.sign(producto_punto(j[1], coeficientes_definitivos[i])) == j[0]:\n",
    "            correcto = correcto + 1\n",
    "        contador = contador + 1\n",
    "    \n",
    "    precision_testeo.append((correcto/contador)*100)\n",
    "    eje_n.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_testeo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $ \n",
    "\n",
    "$ Analisis \\ de \\ todos \\ los \\ metodos $ \n",
    "\n",
    "$ $ \n",
    "\n",
    "Notemos que en todos los métodos se obtienen precisiones muy altas, por ende podemos decir que todos son buenos. Sin embargo, tanto en boosting como regresiones polinomiales se obtienen precisiones similares que son cercanas al 70 %, a diferencia de random forest que se obtiene una precisión cercana al 80% por ende, decimos que el mejor método es el de random forest. \\\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $ \n",
    "\n",
    "$ BONUS $ \n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el bonus el método alternativo que propusimos es un método basado en los valores P de los coeficientes de las regresiones lineales. Para esta lo que hacemos es realizar una regresión lineal para cada una de las variables en donde obtenemos los valores P para cada uno de estos casos. Una vez hecho esto, se realiza el siguiente experimento (Como recordatorio, entre menor valor P, mejor, porque hay más probabilidades de que el coeficiente sea distinto a 0):\n",
    "\n",
    "Se define un porcentaje y se elijen todos los coeficiente que tienen valor P menor a ese porcentaje y se realiza una regresión con todos estas variables. Luego de eso se calcula el error de testeo. Así graficamos el error en función de ese porcentaje y obtenemos el porcentaje optimo y ese estaría siendo nuestro modelo a utilizar.\n",
    "\n",
    "Recordemos que la regresión de esta parte ya no es logistica, sino que es sobre el valor de Variación Porcentual. \n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformacion_datos(X, d):\n",
    "    nuevo_X = []\n",
    "    for i in range(len(X)):\n",
    "        lista = []\n",
    "        for j in range(d):\n",
    "            lista.append(X[i][0]**(j+1))\n",
    "        nuevo_X.append(lista)\n",
    "    return nuevo_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_2014 = pd.read_csv(\"2014_Financial_Data.csv\")\n",
    "archivo_2015 = pd.read_csv(\"2015_Financial_Data.csv\")\n",
    "archivo_2016 = pd.read_csv(\"2016_Financial_Data.csv\")\n",
    "archivo_2017 = pd.read_csv(\"2017_Financial_Data.csv\")\n",
    "archivo_2018 = pd.read_csv(\"2018_Financial_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implementacion_polinomial(numero_atributo):\n",
    "    \n",
    "    nombres_2014 = []\n",
    "\n",
    "    for k in archivo_2014:\n",
    "        nombres_2014.append(k)\n",
    "    \n",
    "    nombres_2014.remove(nombres_2014[len(nombres_2014)-1])\n",
    "    nombres_2014.remove(nombres_2014[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2015 = []\n",
    "\n",
    "    for k in archivo_2015:\n",
    "        nombres_2015.append(k)\n",
    "    \n",
    "    nombres_2015.remove(nombres_2015[len(nombres_2015)-1])\n",
    "    nombres_2015.remove(nombres_2015[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2016 = []\n",
    "\n",
    "    for k in archivo_2016:\n",
    "        nombres_2016.append(k)\n",
    "    \n",
    "    nombres_2016.remove(nombres_2016[len(nombres_2016)-1])\n",
    "    nombres_2016.remove(nombres_2016[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2017 = []\n",
    "\n",
    "    for k in archivo_2017:\n",
    "        nombres_2017.append(k)\n",
    "    \n",
    "    nombres_2017.remove(nombres_2017[len(nombres_2017)-1])\n",
    "    nombres_2017.remove(nombres_2017[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2018 = []\n",
    "\n",
    "    for k in archivo_2018:\n",
    "        nombres_2018.append(k)\n",
    "    \n",
    "    nombres_2018.remove(nombres_2018[len(nombres_2018)-1])\n",
    "    nombres_2018.remove(nombres_2018[0])\n",
    "    \n",
    "    nombres_2014 = []\n",
    "\n",
    "    for k in archivo_2014:\n",
    "        nombres_2014.append(k)\n",
    "    \n",
    "    nombres_2014.remove(nombres_2014[len(nombres_2014)-1])\n",
    "    nombres_2014.remove(nombres_2014[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2015 = []\n",
    "\n",
    "    for k in archivo_2015:\n",
    "        nombres_2015.append(k)\n",
    "    \n",
    "    nombres_2015.remove(nombres_2015[len(nombres_2015)-1])\n",
    "    nombres_2015.remove(nombres_2015[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2016 = []\n",
    "\n",
    "    for k in archivo_2016:\n",
    "        nombres_2016.append(k)\n",
    "    \n",
    "    nombres_2016.remove(nombres_2016[len(nombres_2016)-1])\n",
    "    nombres_2016.remove(nombres_2016[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2017 = []\n",
    "\n",
    "    for k in archivo_2017:\n",
    "        nombres_2017.append(k)\n",
    "    \n",
    "    nombres_2017.remove(nombres_2017[len(nombres_2017)-1])\n",
    "    nombres_2017.remove(nombres_2017[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2018 = []\n",
    "\n",
    "    for k in archivo_2018:\n",
    "        nombres_2018.append(k)\n",
    "    \n",
    "    nombres_2018.remove(nombres_2018[len(nombres_2018)-1])\n",
    "    nombres_2018.remove(nombres_2018[0])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2014 = []\n",
    "    nuevos_nombres_2015 = []\n",
    "    nuevos_nombres_2016 = []\n",
    "    nuevos_nombres_2017 = []\n",
    "    nuevos_nombres_2018 = []\n",
    "\n",
    "    nuevos_nombres_2014.append(nombres_2014[numero_atributo])\n",
    "    nuevos_nombres_2014.append(nombres_2014[len(nombres_2014)-1])\n",
    "\n",
    "    nuevos_nombres_2015.append(nombres_2015[numero_atributo])\n",
    "    nuevos_nombres_2015.append(nombres_2015[len(nombres_2015)-1])\n",
    "\n",
    "    nuevos_nombres_2016.append(nombres_2016[numero_atributo])\n",
    "    nuevos_nombres_2016.append(nombres_2016[len(nombres_2016)-1])\n",
    "\n",
    "    nuevos_nombres_2017.append(nombres_2017[numero_atributo])\n",
    "    nuevos_nombres_2017.append(nombres_2017[len(nombres_2017)-1])\n",
    "\n",
    "    nuevos_nombres_2018.append(nombres_2018[numero_atributo])\n",
    "    nuevos_nombres_2018.append(nombres_2018[len(nombres_2018)-1])\n",
    "    \n",
    "    # Se eliminan los datos NAN\n",
    "\n",
    "    nuevo_archivo_2014 = archivo_2014.dropna(subset=nuevos_nombres_2014)\n",
    "    nuevo_archivo_2015 = archivo_2015.dropna(subset=nuevos_nombres_2015)\n",
    "    nuevo_archivo_2016 = archivo_2016.dropna(subset=nuevos_nombres_2016)\n",
    "    nuevo_archivo_2017 = archivo_2017.dropna(subset=nuevos_nombres_2017)\n",
    "    nuevo_archivo_2018 = archivo_2018.dropna(subset=nuevos_nombres_2018)\n",
    "    \n",
    "    X_entrenamiento = []\n",
    "    Y_entrenamiento = []\n",
    "\n",
    "    #------------------------------------\n",
    "\n",
    "    for k in nuevo_archivo_2014[nuevos_nombres_2014[0]]:\n",
    "        X_entrenamiento.append([k])\n",
    "\n",
    "    for h in nuevo_archivo_2014[nuevos_nombres_2014[1]]:\n",
    "        Y_entrenamiento.append(h)\n",
    "\n",
    "    #------------------------------------\n",
    "\n",
    "    for k in nuevo_archivo_2015[nuevos_nombres_2015[0]]:\n",
    "        X_entrenamiento.append([k])\n",
    "\n",
    "    for h in nuevo_archivo_2015[nuevos_nombres_2015[1]]:\n",
    "        Y_entrenamiento.append(h)\n",
    "\n",
    "    #------------------------------------\n",
    "\n",
    "    for k in nuevo_archivo_2016[nuevos_nombres_2016[0]]:\n",
    "        X_entrenamiento.append([k])\n",
    "\n",
    "    for h in nuevo_archivo_2016[nuevos_nombres_2016[1]]:\n",
    "        Y_entrenamiento.append(h)\n",
    "\n",
    "    #------------------------------------\n",
    "\n",
    "    for k in nuevo_archivo_2017[nuevos_nombres_2017[0]]:\n",
    "        X_entrenamiento.append([k])\n",
    "\n",
    "    for h in nuevo_archivo_2017[nuevos_nombres_2017[1]]:\n",
    "        Y_entrenamiento.append(h)\n",
    "\n",
    "    #------------------------------------\n",
    "    \n",
    "    X_testeo = []\n",
    "    Y_testeo = []\n",
    "\n",
    "    #------------------------------------\n",
    "\n",
    "    for k in nuevo_archivo_2018[nuevos_nombres_2018[0]]:\n",
    "        X_testeo.append([k])\n",
    "\n",
    "    for h in nuevo_archivo_2018[nuevos_nombres_2018[1]]:\n",
    "        Y_testeo.append(h)\n",
    "\n",
    "    #------------------------------------\n",
    "    \n",
    "    D = 10\n",
    "    errores = []\n",
    "    eje_d = []\n",
    "\n",
    "    for d in range(1, D+1):    \n",
    "        nuevo_X = transformacion_datos(X_entrenamiento, d)\n",
    "        nuevo_Y = Y_entrenamiento\n",
    "        reg = LinearRegression().fit(np.array(nuevo_X), np.array(nuevo_Y))\n",
    "        coeficientes = list(reg.coef_)\n",
    "        coeficientes.append(reg.intercept_)\n",
    "    \n",
    "        X_testing = transformacion_datos(X_testeo, d)\n",
    "    \n",
    "        predicciones = []\n",
    "    \n",
    "        error_abs = []\n",
    "    \n",
    "        for i in range(len(Y_testeo)):\n",
    "            suma = 0\n",
    "            for j in range(len(coeficientes)-1):\n",
    "                suma = suma + X_testing[i][j]*coeficientes[j]\n",
    "            suma = suma + coeficientes[len(coeficientes)-1]\n",
    "            predicciones.append(suma)\n",
    "            error_abs.append(abs(suma-Y_entrenamiento[i])) \n",
    "    \n",
    "        error = np.mean(error_abs)\n",
    "        \n",
    "        errores.append(error)\n",
    "        eje_d.append(d)\n",
    "    \n",
    "    return [errores, eje_d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $\n",
    "\n",
    "$ Implementacion \\ Polinomial $\n",
    "\n",
    "$ $\n",
    "\n",
    "Ahora pasamos a mostrar la implementación polinomial. Lo que haremos es que para cada variable calculamos la regresión hasta polinomio de grado $10$ y elegimos el minimo. Luego de esto hacemos esto para todas las variables y graficamos el error en función del número de variable. Luego de esto, escogemos este valor que minimiza que para nuestro caso es el parametro 205 con un error de 41.69 (Este error es el error promedio normal i.e. $ \\sum_{i=1}^{n} \\frac{|valor real - valor predecido|}{n} $), y luego graficamos para este parametro su error en función del grado polinomial y nos damos cuenta que este error se da para el polinomio de grado 1. \n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eje_n = []\n",
    "minimo_error = []\n",
    "tiempo_acumulado = 0\n",
    "\n",
    "for n in range(220):\n",
    "    start = time.time()\n",
    "    output = implementacion_polinomial(n)\n",
    "    eje_n.append(n)\n",
    "    minimo_error.append(min(output[0]))\n",
    "    end = time.time()\n",
    "    tiempo_acumulado = tiempo_acumulado + (end-start)\n",
    "    if n % 20 == 0:\n",
    "        print(\"Iteración: \", n)\n",
    "        print(\"Tiempo: \", tiempo_acumulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eje_n, minimo_error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(minimo_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_minimo = eje_n[minimo_error.index(min(minimo_error))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_minimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = implementacion_polinomial(n_minimo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output[1], output[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $ \n",
    "\n",
    "$ Random \\ Forest $ \n",
    "\n",
    "$ $\n",
    "\n",
    "Ahora aplicamos Random Forest y para este caso pondremos como variable el número de atributos utilizado en este algoritmo y graficaremos el error en función de este número de atributos. Como se observa en el grafico presentado, el minimo se da cuando se escogen 9 parametros y para este caso se obtiene un error promedio (Este error es el error promedio normal i.e. $ \\sum_{i=1}^{n} \\frac{|valor real - valor predecido|}{n} $) de 153.22.\n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(semilla, nro_atributos, nro_elecciones):\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    \n",
    "    archivo_2014 = pd.read_csv(\"2014_Financial_Data.csv\")\n",
    "    archivo_2015 = pd.read_csv(\"2015_Financial_Data.csv\")\n",
    "    archivo_2016 = pd.read_csv(\"2016_Financial_Data.csv\")\n",
    "    archivo_2017 = pd.read_csv(\"2017_Financial_Data.csv\")\n",
    "    archivo_2018 = pd.read_csv(\"2018_Financial_Data.csv\")\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    \n",
    "    nombres_2014 = []\n",
    "\n",
    "    for k in archivo_2014:\n",
    "        nombres_2014.append(k)\n",
    "    \n",
    "    nombres_2014.remove(nombres_2014[len(nombres_2014)-1])\n",
    "    nombres_2014.remove(nombres_2014[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2015 = []\n",
    "\n",
    "    for k in archivo_2015:\n",
    "        nombres_2015.append(k)\n",
    "    \n",
    "    nombres_2015.remove(nombres_2015[len(nombres_2015)-1])\n",
    "    nombres_2015.remove(nombres_2015[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2016 = []\n",
    "\n",
    "    for k in archivo_2016:\n",
    "        nombres_2016.append(k)\n",
    "    \n",
    "    nombres_2016.remove(nombres_2016[len(nombres_2016)-1])\n",
    "    nombres_2016.remove(nombres_2016[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2017 = []\n",
    "\n",
    "    for k in archivo_2017:\n",
    "        nombres_2017.append(k)\n",
    "    \n",
    "    nombres_2017.remove(nombres_2017[len(nombres_2017)-1])\n",
    "    nombres_2017.remove(nombres_2017[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2018 = []\n",
    "\n",
    "    for k in archivo_2018:\n",
    "        nombres_2018.append(k)\n",
    "    \n",
    "    nombres_2018.remove(nombres_2018[len(nombres_2018)-1])\n",
    "    nombres_2018.remove(nombres_2018[0])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    # Determinar los atributos \n",
    "    \n",
    "    random.seed(semilla)\n",
    "    \n",
    "    eleccion = []\n",
    "    \n",
    "    for i in range(nro_atributos):\n",
    "        eleccion.append(random.randint(0, 200))\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2014 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2014.append(nombres_2014[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2014.append(nombres_2014[len(nombres_2014)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2015 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2015.append(nombres_2015[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2015.append(nombres_2015[len(nombres_2015)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2016 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2016.append(nombres_2016[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2016.append(nombres_2016[len(nombres_2016)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2017 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2017.append(nombres_2017[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2017.append(nombres_2017[len(nombres_2017)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2018 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2018.append(nombres_2018[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2018.append(nombres_2018[len(nombres_2018)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevo_archivo_2014 = archivo_2014.dropna(subset=nuevos_nombres_2014)\n",
    "    nuevo_archivo_2015 = archivo_2015.dropna(subset=nuevos_nombres_2015)\n",
    "    nuevo_archivo_2016 = archivo_2016.dropna(subset=nuevos_nombres_2016)\n",
    "    nuevo_archivo_2017 = archivo_2017.dropna(subset=nuevos_nombres_2017)\n",
    "    nuevo_archivo_2018 = archivo_2018.dropna(subset=nuevos_nombres_2018)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2014 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2014:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2014[k]:\n",
    "            lista.append(j)\n",
    "        data_2014.append(lista)\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2015 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2015:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2015[k]:\n",
    "            lista.append(j)\n",
    "        data_2015.append(lista)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2016 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2016:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2016[k]:\n",
    "            lista.append(j)\n",
    "        data_2016.append(lista)\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2017 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2017:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2017[k]:\n",
    "            lista.append(j)\n",
    "        data_2017.append(lista)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2018 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2018:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2018[k]:\n",
    "            lista.append(j)\n",
    "        data_2018.append(lista)\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    X_entrenamiento = []\n",
    "    Y_entrenamiento = []\n",
    "    \n",
    "    for i in range(len(data_2014[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2014)-1):\n",
    "            lista.append(data_2014[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2014[len(data_2014)-1][i])\n",
    "    \n",
    "    for i in range(len(data_2015[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2015)-1):\n",
    "            lista.append(data_2015[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2015[len(data_2015)-1][i])\n",
    "    \n",
    "    for i in range(len(data_2016[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2016)-1):\n",
    "            lista.append(data_2016[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2016[len(data_2016)-1][i])\n",
    "    \n",
    "    for i in range(len(data_2017[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2017)-1):\n",
    "            lista.append(data_2017[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2017[len(data_2017)-1][i])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for i in range(len(data_2018[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2018)-1):\n",
    "            lista.append(data_2018[j][i])\n",
    "        X_test.append(lista)\n",
    "        Y_test.append(data_2018[len(data_2018)-1][i])\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    intervalos = []\n",
    "    \n",
    "    for h in range(nro_elecciones):\n",
    "        numero = random.randint(0, 8000)\n",
    "        intervalos.append([numero, numero + 2000])\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    predicciones = []\n",
    "    \n",
    "    for k in intervalos:\n",
    "        dato_X = np.array(X_entrenamiento[k[0]:k[1]])\n",
    "        dato_Y = np.array(Y_entrenamiento[k[0]:k[1]])\n",
    "        reg = LinearRegression().fit(dato_X, dato_Y)\n",
    "        predicciones.append(reg.predict(np.array(X_test)))\n",
    "        \n",
    "    prom_predict = []\n",
    "    \n",
    "    for i in range(len(predicciones[0])):\n",
    "        valor = 0\n",
    "        for j in range(len(predicciones)):\n",
    "            valor = valor + predicciones[j][i]\n",
    "        valor = valor/len(predicciones)\n",
    "        prom_predict.append(valor)\n",
    "    \n",
    "    errores = []\n",
    "    \n",
    "    for i in range(len(prom_predict)):\n",
    "        errores.append(abs(float(prom_predict[i]) - Y_test[i]))\n",
    "    \n",
    "    error = np.mean(errores)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eje_n = []\n",
    "errores = []\n",
    "\n",
    "N = 20\n",
    "nro_elecciones = 100\n",
    "\n",
    "tiempo_total = 0\n",
    "\n",
    "for n in range(1, N+1):\n",
    "    start = time.time()\n",
    "    \n",
    "    errores.append(random_forest(2222, n, nro_elecciones))\n",
    "    eje_n.append(n)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    tiempo_total = tiempo_total + (end-start)\n",
    "    \n",
    "    print(\"Iteración: \", n)\n",
    "    print(\"Tiempo: \", end-start)\n",
    "    print(\"-----------\")\n",
    "\n",
    "print(\"-----------\")\n",
    "print(\"Tiempo Total: \", tiempo_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eje_n, errores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eje_n[errores.index(min(errores))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $ \n",
    "\n",
    "$ Aplicacion \\ del \\ nuevo \\ metodo $\n",
    "\n",
    "$ $\n",
    "\n",
    "Este método se aplica justamente como se propuso, en donde obtuvimos que el porcentaje optimo es $ 51 $ y aquí se obtuvo que para este modelo se utilizan 13 variables obteniendo un error de 30.1 \n",
    "\n",
    "$ $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuevo_metodo(indices):\n",
    "\n",
    "    #-------------------------------------------\n",
    "    \n",
    "    archivo_2014 = pd.read_csv(\"2014_Financial_Data.csv\")\n",
    "    archivo_2015 = pd.read_csv(\"2015_Financial_Data.csv\")\n",
    "    archivo_2016 = pd.read_csv(\"2016_Financial_Data.csv\")\n",
    "    archivo_2017 = pd.read_csv(\"2017_Financial_Data.csv\")\n",
    "    archivo_2018 = pd.read_csv(\"2018_Financial_Data.csv\")\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    \n",
    "    nombres_2014 = []\n",
    "\n",
    "    for k in archivo_2014:\n",
    "        nombres_2014.append(k)\n",
    "    \n",
    "    nombres_2014.remove(nombres_2014[len(nombres_2014)-1])\n",
    "    nombres_2014.remove(nombres_2014[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2015 = []\n",
    "\n",
    "    for k in archivo_2015:\n",
    "        nombres_2015.append(k)\n",
    "    \n",
    "    nombres_2015.remove(nombres_2015[len(nombres_2015)-1])\n",
    "    nombres_2015.remove(nombres_2015[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2016 = []\n",
    "\n",
    "    for k in archivo_2016:\n",
    "        nombres_2016.append(k)\n",
    "    \n",
    "    nombres_2016.remove(nombres_2016[len(nombres_2016)-1])\n",
    "    nombres_2016.remove(nombres_2016[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2017 = []\n",
    "\n",
    "    for k in archivo_2017:\n",
    "        nombres_2017.append(k)\n",
    "    \n",
    "    nombres_2017.remove(nombres_2017[len(nombres_2017)-1])\n",
    "    nombres_2017.remove(nombres_2017[0])\n",
    "\n",
    "    #--------------------------------------------\n",
    "\n",
    "    nombres_2018 = []\n",
    "\n",
    "    for k in archivo_2018:\n",
    "        nombres_2018.append(k)\n",
    "    \n",
    "    nombres_2018.remove(nombres_2018[len(nombres_2018)-1])\n",
    "    nombres_2018.remove(nombres_2018[0])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    eleccion = indices\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2014 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2014.append(nombres_2014[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2014.append(nombres_2014[len(nombres_2014)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2015 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2015.append(nombres_2015[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2015.append(nombres_2015[len(nombres_2015)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2016 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2016.append(nombres_2016[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2016.append(nombres_2016[len(nombres_2016)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2017 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2017.append(nombres_2017[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2017.append(nombres_2017[len(nombres_2017)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevos_nombres_2018 = []\n",
    "    \n",
    "    for j in range(len(eleccion)):\n",
    "        nuevos_nombres_2018.append(nombres_2018[eleccion[j]])\n",
    "    \n",
    "    nuevos_nombres_2018.append(nombres_2018[len(nombres_2018)-1])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    nuevo_archivo_2014 = archivo_2014.dropna(subset=nuevos_nombres_2014)\n",
    "    nuevo_archivo_2015 = archivo_2015.dropna(subset=nuevos_nombres_2015)\n",
    "    nuevo_archivo_2016 = archivo_2016.dropna(subset=nuevos_nombres_2016)\n",
    "    nuevo_archivo_2017 = archivo_2017.dropna(subset=nuevos_nombres_2017)\n",
    "    nuevo_archivo_2018 = archivo_2018.dropna(subset=nuevos_nombres_2018)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2014 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2014:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2014[k]:\n",
    "            lista.append(j)\n",
    "        data_2014.append(lista)\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2015 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2015:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2015[k]:\n",
    "            lista.append(j)\n",
    "        data_2015.append(lista)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2016 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2016:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2016[k]:\n",
    "            lista.append(j)\n",
    "        data_2016.append(lista)\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2017 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2017:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2017[k]:\n",
    "            lista.append(j)\n",
    "        data_2017.append(lista)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    data_2018 = []\n",
    "    \n",
    "    for k in nuevos_nombres_2018:\n",
    "        lista = []\n",
    "        for j in nuevo_archivo_2018[k]:\n",
    "            lista.append(j)\n",
    "        data_2018.append(lista)\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    X_entrenamiento = []\n",
    "    Y_entrenamiento = []\n",
    "    \n",
    "    for i in range(len(data_2014[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2014)-1):\n",
    "            lista.append(data_2014[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2014[len(data_2014)-1][i])\n",
    "    \n",
    "    for i in range(len(data_2015[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2015)-1):\n",
    "            lista.append(data_2015[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2015[len(data_2015)-1][i])\n",
    "    \n",
    "    for i in range(len(data_2016[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2016)-1):\n",
    "            lista.append(data_2016[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2016[len(data_2016)-1][i])\n",
    "    \n",
    "    for i in range(len(data_2017[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2017)-1):\n",
    "            lista.append(data_2017[j][i])\n",
    "        X_entrenamiento.append(lista)\n",
    "        Y_entrenamiento.append(data_2017[len(data_2017)-1][i])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for i in range(len(data_2018[0])):\n",
    "        lista = []\n",
    "        for j in range(len(data_2018)-1):\n",
    "            lista.append(data_2018[j][i])\n",
    "        X_test.append(lista)\n",
    "        Y_test.append(data_2018[len(data_2018)-1][i])\n",
    "        \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    dato_X = np.array(X_entrenamiento)\n",
    "    dato_Y = np.array(Y_entrenamiento)\n",
    "    \n",
    "    regresion = LinearRegression().fit(dato_X, dato_Y)\n",
    "    \n",
    "    predicciones = regresion.predict(np.array(X_test))\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    errores = []\n",
    "    \n",
    "    for i in range(len(predicciones)):\n",
    "        errores.append(abs(float(predicciones[i]) - Y_test[i]))\n",
    "    \n",
    "    error = np.mean(errores)\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    #Calculo del valor p\n",
    "    \n",
    "    mod = sm.OLS(dato_Y,dato_X)\n",
    "    fii = mod.fit()\n",
    "    p_values = list(fii.summary2().tables[1]['P>|t|'])\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    t = p_values.index(min(p_values))\n",
    "    indices[t]\n",
    "    \n",
    "    return [error, indices[t], min(p_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_indices = []\n",
    "\n",
    "p = 0.1\n",
    "\n",
    "tiempo_total = 0\n",
    "\n",
    "for i in range(220):\n",
    "    start = time.time()\n",
    "    \n",
    "    output = nuevo_metodo([i])\n",
    "    \n",
    "    mejores_indices.append([output[1], output[2]])\n",
    "    end = time.time()\n",
    "    \n",
    "    tiempo_total = tiempo_total + (end-start)\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        \n",
    "        print(\"Iteración: \", i)\n",
    "        print(\"Tiempo: \", tiempo_total)\n",
    "        print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mejores_indices_umbral(p):\n",
    "    indices_definitivos = []\n",
    "    for i in range(len(mejores_indices)):\n",
    "        if mejores_indices[i][1] <= p:\n",
    "            indices_definitivos.append(mejores_indices[i][0])\n",
    "    return indices_definitivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errores = []\n",
    "eje_p = []\n",
    "P = 70\n",
    "\n",
    "tiempo_total = 0\n",
    "\n",
    "for p in range(P):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    prob = p/100\n",
    "    errores.append(nuevo_metodo(mejores_indices_umbral(prob))[0])\n",
    "    eje_p.append(p)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Iteración: \", p)\n",
    "    print(\"Tiempo: \", end-start)\n",
    "    print(\"--------\")\n",
    "    \n",
    "    tiempo_total = tiempo_total + (end-start)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"Tiempo total: \", tiempo_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eje_p, errores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eje_p[errores.index(min(errores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 unidades es el minimo error y se encuentra cuando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_definitivos = []\n",
    "for i in range(len(mejores_indices)):\n",
    "    if mejores_indices[i][1] <= 0.51:\n",
    "        indices_definitivos.append(mejores_indices[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_definitivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ $\n",
    "\n",
    "$ Analisis \\ de \\ Resultados $ \n",
    "\n",
    "$ $\n",
    "\n",
    "Notemos que para este caso random forest funciona mal en comparación al método polinomial y al método propuesto, y esto es porque la clave en este caso es encontrar las variables que son más significativas para predecir. Cuando comparamos la regresión polinomial notamos que el mejor caso es un polinomio de grado uno con un error mayor a 40, sin embargo, en nuestro metodo propuesto logramos un error cercano a 30, es decir que es el más eficiente de todos, y esto es justamente porque en este método encontramos estadisticamente las variables más significativas\n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
