{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "WFFZzY7QZ7Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start execution"
      ],
      "metadata": {
        "id": "Os39ENMInhJy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tyTPRLRanOFQ"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()"
      ],
      "metadata": {
        "id": "BVt1Dkx7nka6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setting the environment"
      ],
      "metadata": {
        "id": "_8w9agJHogyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q resampy"
      ],
      "metadata": {
        "id": "gUaUA3xknl_S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Libraries"
      ],
      "metadata": {
        "id": "FIYlmgd7ope3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import resampy\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5tJA9mJSokvh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "C5ZBDKhReRLX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "pIug8HyM7BzF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preparation"
      ],
      "metadata": {
        "id": "VFkVTBTTo7fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ0iM-5poktv",
        "outputId": "7f58ea66-1a3f-4172-a580-796c53dba32a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_general = 'drive/MyDrive/Profesional_Academico/Github_Personal/ML_AI_Contents/09.Deep_Learning/73.Audio_NN_Scratch/processed'"
      ],
      "metadata": {
        "id": "JE_vFR85pLGT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Build datasets"
      ],
      "metadata": {
        "id": "q9BLbsj7aEZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Train"
      ],
      "metadata": {
        "id": "doQwyWptcliG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(1, 10 + 1):\n",
        "\n",
        "  path_part = f'{path_general}/train/{i}'\n",
        "\n",
        "  part_files = os.listdir(path_part)\n",
        "\n",
        "  for p_f in part_files:\n",
        "\n",
        "    path_elem = f'{path_part}/{p_f}'\n",
        "\n",
        "    elem_part = np.load(path_elem)\n",
        "\n",
        "    X_train.append(elem_part)\n",
        "    y_train.append(i)"
      ],
      "metadata": {
        "id": "X2CgInloajx5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "vqGitlNSaHtW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_1 = (y_train == 1)*1\n",
        "y_train_2 = (y_train == 2)*1\n",
        "y_train_3 = (y_train == 3)*1\n",
        "y_train_4 = (y_train == 4)*1\n",
        "y_train_5 = (y_train == 5)*1\n",
        "y_train_6 = (y_train == 6)*1\n",
        "y_train_7 = (y_train == 7)*1\n",
        "y_train_8 = (y_train == 8)*1\n",
        "y_train_9 = (y_train == 9)*1\n",
        "y_train_10 = (y_train == 10)*1"
      ],
      "metadata": {
        "id": "5h3Xfgypb3u6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array([y_train_1, y_train_2, y_train_3, y_train_4, y_train_5, y_train_6, y_train_7, y_train_8, y_train_9, y_train_10])"
      ],
      "metadata": {
        "id": "bTIsm8wOcYEf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.transpose()"
      ],
      "metadata": {
        "id": "lYdJDEhbctHR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clc6f6tedZv8",
        "outputId": "696549c6-10e1-4f11-962a-6f5192e24595"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5239, 40, 174, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycxMjjmJda3G",
        "outputId": "c5133793-ee5c-4857-ef0e-b39c4fd45b76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5239, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Val"
      ],
      "metadata": {
        "id": "oITC2WMUc4N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "for i in range(1, 10 + 1):\n",
        "\n",
        "  path_part = f'{path_general}/val/{i}'\n",
        "\n",
        "  part_files = os.listdir(path_part)\n",
        "\n",
        "  for p_f in part_files:\n",
        "\n",
        "    path_elem = f'{path_part}/{p_f}'\n",
        "\n",
        "    elem_part = np.load(path_elem)\n",
        "\n",
        "    X_val.append(elem_part)\n",
        "    y_val.append(i)"
      ],
      "metadata": {
        "id": "9OE99olwc4N1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "HcFYWiIsc4N1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_1 = (y_val == 1)*1\n",
        "y_val_2 = (y_val == 2)*1\n",
        "y_val_3 = (y_val == 3)*1\n",
        "y_val_4 = (y_val == 4)*1\n",
        "y_val_5 = (y_val == 5)*1\n",
        "y_val_6 = (y_val == 6)*1\n",
        "y_val_7 = (y_val == 7)*1\n",
        "y_val_8 = (y_val == 8)*1\n",
        "y_val_9 = (y_val == 9)*1\n",
        "y_val_10 = (y_val == 10)*1"
      ],
      "metadata": {
        "id": "vsih6tz3c4N1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = np.array([y_val_1, y_val_2, y_val_3, y_val_4, y_val_5, y_val_6, y_val_7, y_val_8, y_val_9, y_val_10])"
      ],
      "metadata": {
        "id": "iiMiIQG4c4N1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = y_val.transpose()"
      ],
      "metadata": {
        "id": "b-EKkpl4c4N2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHJVIxSWc4N2",
        "outputId": "2056a9fc-724b-4ef3-8387-30125441ff3e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1746, 40, 174, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imnfWMiCc3tx",
        "outputId": "7e062df9-fcd7-46de-a83e-68cae63ec22f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1746, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Test"
      ],
      "metadata": {
        "id": "XXXEIxSLdjyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(1, 10 + 1):\n",
        "\n",
        "  path_part = f'{path_general}/test/{i}'\n",
        "\n",
        "  part_files = os.listdir(path_part)\n",
        "\n",
        "  for p_f in part_files:\n",
        "\n",
        "    path_elem = f'{path_part}/{p_f}'\n",
        "\n",
        "    elem_part = np.load(path_elem)\n",
        "\n",
        "    X_test.append(elem_part)\n",
        "    y_test.append(i)"
      ],
      "metadata": {
        "id": "g6ia5AdWdjyT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "n0PTJ-14djyT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_1 = (y_test == 1)*1\n",
        "y_test_2 = (y_test == 2)*1\n",
        "y_test_3 = (y_test == 3)*1\n",
        "y_test_4 = (y_test == 4)*1\n",
        "y_test_5 = (y_test == 5)*1\n",
        "y_test_6 = (y_test == 6)*1\n",
        "y_test_7 = (y_test == 7)*1\n",
        "y_test_8 = (y_test == 8)*1\n",
        "y_test_9 = (y_test == 9)*1\n",
        "y_test_10 = (y_test == 10)*1"
      ],
      "metadata": {
        "id": "OOqw6elwdjyU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.array([y_test_1, y_test_2, y_test_3, y_test_4, y_test_5, y_test_6, y_test_7, y_test_8, y_test_9, y_test_10])"
      ],
      "metadata": {
        "id": "1tA3g1o0djyU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.transpose()"
      ],
      "metadata": {
        "id": "v2yfTF9tdjyU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_0ETRzWdjyU",
        "outputId": "473998c6-14d7-4d87-fecf-092950b62693"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1747, 40, 174, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XVXGf4jdjyU",
        "outputId": "51d0636f-c655-4ed0-b9b2-412343a913a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1747, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Create model"
      ],
      "metadata": {
        "id": "z-dwnsj4eBuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 40\n",
        "num_columns = 174\n",
        "num_channels = 1\n",
        "num_labels = 10\n",
        "filter_size = 2\n",
        "\n",
        "# Construct model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))"
      ],
      "metadata": {
        "id": "YdGxOMIcc3m8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001"
      ],
      "metadata": {
        "id": "htpd_47airrn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = lr), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EKGOZzGhe6AB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train"
      ],
      "metadata": {
        "id": "lzU4fQSse2XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1000"
      ],
      "metadata": {
        "id": "M6-neexGc3ij"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 50, epochs = n_epochs, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiuAKjhve-oG",
        "outputId": "32dc5b16-0989-4e09-f91a-31b42f61fb4b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "105/105 [==============================] - 5s 12ms/step - loss: 5.5650 - accuracy: 0.1433 - val_loss: 2.4641 - val_accuracy: 0.1592\n",
            "Epoch 2/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 3.0641 - accuracy: 0.2140 - val_loss: 2.1489 - val_accuracy: 0.2325\n",
            "Epoch 3/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 2.4322 - accuracy: 0.2787 - val_loss: 1.9969 - val_accuracy: 0.2795\n",
            "Epoch 4/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 2.0680 - accuracy: 0.3304 - val_loss: 1.8727 - val_accuracy: 0.3333\n",
            "Epoch 5/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.8688 - accuracy: 0.3730 - val_loss: 1.8010 - val_accuracy: 0.3809\n",
            "Epoch 6/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.7561 - accuracy: 0.3923 - val_loss: 1.7827 - val_accuracy: 0.3814\n",
            "Epoch 7/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.6740 - accuracy: 0.4213 - val_loss: 1.7329 - val_accuracy: 0.4210\n",
            "Epoch 8/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.5910 - accuracy: 0.4444 - val_loss: 1.6740 - val_accuracy: 0.4507\n",
            "Epoch 9/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.5440 - accuracy: 0.4552 - val_loss: 1.6305 - val_accuracy: 0.4656\n",
            "Epoch 10/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.4860 - accuracy: 0.4799 - val_loss: 1.5972 - val_accuracy: 0.4834\n",
            "Epoch 11/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.4599 - accuracy: 0.4955 - val_loss: 1.5904 - val_accuracy: 0.4874\n",
            "Epoch 12/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.4186 - accuracy: 0.4993 - val_loss: 1.5573 - val_accuracy: 0.4891\n",
            "Epoch 13/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.3843 - accuracy: 0.5142 - val_loss: 1.5268 - val_accuracy: 0.5006\n",
            "Epoch 14/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.3627 - accuracy: 0.5207 - val_loss: 1.5091 - val_accuracy: 0.5074\n",
            "Epoch 15/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.3310 - accuracy: 0.5293 - val_loss: 1.4756 - val_accuracy: 0.5195\n",
            "Epoch 16/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2999 - accuracy: 0.5390 - val_loss: 1.4671 - val_accuracy: 0.5281\n",
            "Epoch 17/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.2628 - accuracy: 0.5581 - val_loss: 1.4137 - val_accuracy: 0.5510\n",
            "Epoch 18/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2558 - accuracy: 0.5654 - val_loss: 1.4064 - val_accuracy: 0.5533\n",
            "Epoch 19/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.2368 - accuracy: 0.5652 - val_loss: 1.3897 - val_accuracy: 0.5619\n",
            "Epoch 20/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.2141 - accuracy: 0.5789 - val_loss: 1.3599 - val_accuracy: 0.5693\n",
            "Epoch 21/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.1896 - accuracy: 0.5843 - val_loss: 1.3438 - val_accuracy: 0.5756\n",
            "Epoch 22/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.1762 - accuracy: 0.5910 - val_loss: 1.3128 - val_accuracy: 0.5848\n",
            "Epoch 23/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.1762 - accuracy: 0.5850 - val_loss: 1.3042 - val_accuracy: 0.5819\n",
            "Epoch 24/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.1280 - accuracy: 0.6043 - val_loss: 1.2732 - val_accuracy: 0.6077\n",
            "Epoch 25/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.1396 - accuracy: 0.5982 - val_loss: 1.2545 - val_accuracy: 0.6002\n",
            "Epoch 26/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.1203 - accuracy: 0.6110 - val_loss: 1.2545 - val_accuracy: 0.6019\n",
            "Epoch 27/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0928 - accuracy: 0.6184 - val_loss: 1.2344 - val_accuracy: 0.6145\n",
            "Epoch 28/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0886 - accuracy: 0.6207 - val_loss: 1.2091 - val_accuracy: 0.6237\n",
            "Epoch 29/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0561 - accuracy: 0.6362 - val_loss: 1.1961 - val_accuracy: 0.6208\n",
            "Epoch 30/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0474 - accuracy: 0.6400 - val_loss: 1.1699 - val_accuracy: 0.6220\n",
            "Epoch 31/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0368 - accuracy: 0.6385 - val_loss: 1.1773 - val_accuracy: 0.6300\n",
            "Epoch 32/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0177 - accuracy: 0.6515 - val_loss: 1.1541 - val_accuracy: 0.6334\n",
            "Epoch 33/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0044 - accuracy: 0.6530 - val_loss: 1.1235 - val_accuracy: 0.6460\n",
            "Epoch 34/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9942 - accuracy: 0.6583 - val_loss: 1.1390 - val_accuracy: 0.6357\n",
            "Epoch 35/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9752 - accuracy: 0.6555 - val_loss: 1.1166 - val_accuracy: 0.6449\n",
            "Epoch 36/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9651 - accuracy: 0.6717 - val_loss: 1.1008 - val_accuracy: 0.6369\n",
            "Epoch 37/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9562 - accuracy: 0.6684 - val_loss: 1.0896 - val_accuracy: 0.6552\n",
            "Epoch 38/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9356 - accuracy: 0.6854 - val_loss: 1.0454 - val_accuracy: 0.6798\n",
            "Epoch 39/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9346 - accuracy: 0.6818 - val_loss: 1.0763 - val_accuracy: 0.6598\n",
            "Epoch 40/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9171 - accuracy: 0.6900 - val_loss: 1.0479 - val_accuracy: 0.6707\n",
            "Epoch 41/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9115 - accuracy: 0.6873 - val_loss: 1.0211 - val_accuracy: 0.6804\n",
            "Epoch 42/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9043 - accuracy: 0.6875 - val_loss: 1.0085 - val_accuracy: 0.6861\n",
            "Epoch 43/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8908 - accuracy: 0.6935 - val_loss: 1.0152 - val_accuracy: 0.6821\n",
            "Epoch 44/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8745 - accuracy: 0.6980 - val_loss: 0.9772 - val_accuracy: 0.7022\n",
            "Epoch 45/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8589 - accuracy: 0.7047 - val_loss: 0.9768 - val_accuracy: 0.7039\n",
            "Epoch 46/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8524 - accuracy: 0.7032 - val_loss: 0.9515 - val_accuracy: 0.7085\n",
            "Epoch 47/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8484 - accuracy: 0.7122 - val_loss: 0.9731 - val_accuracy: 0.6942\n",
            "Epoch 48/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8422 - accuracy: 0.7104 - val_loss: 0.9266 - val_accuracy: 0.7211\n",
            "Epoch 49/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8141 - accuracy: 0.7269 - val_loss: 0.9181 - val_accuracy: 0.7194\n",
            "Epoch 50/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8119 - accuracy: 0.7225 - val_loss: 0.9208 - val_accuracy: 0.7222\n",
            "Epoch 51/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8006 - accuracy: 0.7265 - val_loss: 0.9059 - val_accuracy: 0.7199\n",
            "Epoch 52/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8139 - accuracy: 0.7253 - val_loss: 0.9297 - val_accuracy: 0.7119\n",
            "Epoch 53/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7929 - accuracy: 0.7272 - val_loss: 0.9033 - val_accuracy: 0.7188\n",
            "Epoch 54/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7766 - accuracy: 0.7402 - val_loss: 0.8878 - val_accuracy: 0.7297\n",
            "Epoch 55/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7739 - accuracy: 0.7366 - val_loss: 0.8811 - val_accuracy: 0.7377\n",
            "Epoch 56/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7551 - accuracy: 0.7385 - val_loss: 0.8742 - val_accuracy: 0.7291\n",
            "Epoch 57/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7456 - accuracy: 0.7414 - val_loss: 0.8505 - val_accuracy: 0.7314\n",
            "Epoch 58/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7363 - accuracy: 0.7549 - val_loss: 0.8598 - val_accuracy: 0.7423\n",
            "Epoch 59/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7333 - accuracy: 0.7564 - val_loss: 0.8318 - val_accuracy: 0.7388\n",
            "Epoch 60/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7283 - accuracy: 0.7528 - val_loss: 0.8078 - val_accuracy: 0.7612\n",
            "Epoch 61/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7095 - accuracy: 0.7648 - val_loss: 0.8295 - val_accuracy: 0.7411\n",
            "Epoch 62/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7208 - accuracy: 0.7557 - val_loss: 0.8006 - val_accuracy: 0.7554\n",
            "Epoch 63/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6950 - accuracy: 0.7646 - val_loss: 0.8119 - val_accuracy: 0.7457\n",
            "Epoch 64/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6939 - accuracy: 0.7704 - val_loss: 0.7935 - val_accuracy: 0.7503\n",
            "Epoch 65/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6869 - accuracy: 0.7717 - val_loss: 0.7872 - val_accuracy: 0.7646\n",
            "Epoch 66/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6868 - accuracy: 0.7673 - val_loss: 0.7933 - val_accuracy: 0.7451\n",
            "Epoch 67/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6697 - accuracy: 0.7706 - val_loss: 0.7919 - val_accuracy: 0.7468\n",
            "Epoch 68/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6541 - accuracy: 0.7765 - val_loss: 0.7457 - val_accuracy: 0.7680\n",
            "Epoch 69/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6648 - accuracy: 0.7734 - val_loss: 0.7516 - val_accuracy: 0.7732\n",
            "Epoch 70/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6458 - accuracy: 0.7767 - val_loss: 0.7727 - val_accuracy: 0.7577\n",
            "Epoch 71/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6370 - accuracy: 0.7816 - val_loss: 0.7337 - val_accuracy: 0.7755\n",
            "Epoch 72/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6415 - accuracy: 0.7778 - val_loss: 0.7395 - val_accuracy: 0.7726\n",
            "Epoch 73/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6272 - accuracy: 0.7845 - val_loss: 0.7250 - val_accuracy: 0.7709\n",
            "Epoch 74/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6346 - accuracy: 0.7839 - val_loss: 0.7109 - val_accuracy: 0.7755\n",
            "Epoch 75/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6361 - accuracy: 0.7855 - val_loss: 0.6906 - val_accuracy: 0.7875\n",
            "Epoch 76/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6117 - accuracy: 0.7965 - val_loss: 0.6930 - val_accuracy: 0.7904\n",
            "Epoch 77/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6139 - accuracy: 0.7868 - val_loss: 0.6953 - val_accuracy: 0.7852\n",
            "Epoch 78/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6051 - accuracy: 0.7981 - val_loss: 0.6783 - val_accuracy: 0.7875\n",
            "Epoch 79/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6017 - accuracy: 0.7935 - val_loss: 0.6540 - val_accuracy: 0.8013\n",
            "Epoch 80/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6061 - accuracy: 0.7956 - val_loss: 0.6568 - val_accuracy: 0.7955\n",
            "Epoch 81/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.7981 - val_loss: 0.7044 - val_accuracy: 0.7778\n",
            "Epoch 82/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5845 - accuracy: 0.8013 - val_loss: 0.6406 - val_accuracy: 0.8018\n",
            "Epoch 83/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.8114 - val_loss: 0.6401 - val_accuracy: 0.8058\n",
            "Epoch 84/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5676 - accuracy: 0.8040 - val_loss: 0.6508 - val_accuracy: 0.7910\n",
            "Epoch 85/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5602 - accuracy: 0.8078 - val_loss: 0.6242 - val_accuracy: 0.8116\n",
            "Epoch 86/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.8101 - val_loss: 0.6282 - val_accuracy: 0.8030\n",
            "Epoch 87/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.8213 - val_loss: 0.6212 - val_accuracy: 0.8041\n",
            "Epoch 88/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5523 - accuracy: 0.8118 - val_loss: 0.6219 - val_accuracy: 0.8099\n",
            "Epoch 89/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.8131 - val_loss: 0.6406 - val_accuracy: 0.7984\n",
            "Epoch 90/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.8204 - val_loss: 0.6506 - val_accuracy: 0.7990\n",
            "Epoch 91/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5177 - accuracy: 0.8336 - val_loss: 0.6043 - val_accuracy: 0.8093\n",
            "Epoch 92/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5296 - accuracy: 0.8231 - val_loss: 0.6187 - val_accuracy: 0.8104\n",
            "Epoch 93/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5393 - accuracy: 0.8175 - val_loss: 0.6054 - val_accuracy: 0.8116\n",
            "Epoch 94/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.8269 - val_loss: 0.5836 - val_accuracy: 0.8190\n",
            "Epoch 95/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.8240 - val_loss: 0.5936 - val_accuracy: 0.8144\n",
            "Epoch 96/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5258 - accuracy: 0.8208 - val_loss: 0.6195 - val_accuracy: 0.8036\n",
            "Epoch 97/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.8225 - val_loss: 0.6030 - val_accuracy: 0.8058\n",
            "Epoch 98/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5126 - accuracy: 0.8286 - val_loss: 0.5876 - val_accuracy: 0.8156\n",
            "Epoch 99/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4967 - accuracy: 0.8336 - val_loss: 0.5726 - val_accuracy: 0.8156\n",
            "Epoch 100/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4901 - accuracy: 0.8362 - val_loss: 0.5528 - val_accuracy: 0.8288\n",
            "Epoch 101/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5014 - accuracy: 0.8299 - val_loss: 0.5795 - val_accuracy: 0.8144\n",
            "Epoch 102/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4885 - accuracy: 0.8330 - val_loss: 0.5720 - val_accuracy: 0.8127\n",
            "Epoch 103/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.8360 - val_loss: 0.5477 - val_accuracy: 0.8202\n",
            "Epoch 104/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4783 - accuracy: 0.8381 - val_loss: 0.5565 - val_accuracy: 0.8184\n",
            "Epoch 105/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.8347 - val_loss: 0.5306 - val_accuracy: 0.8339\n",
            "Epoch 106/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.8479 - val_loss: 0.5526 - val_accuracy: 0.8242\n",
            "Epoch 107/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.8408 - val_loss: 0.5218 - val_accuracy: 0.8305\n",
            "Epoch 108/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.8458 - val_loss: 0.5375 - val_accuracy: 0.8293\n",
            "Epoch 109/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4512 - accuracy: 0.8483 - val_loss: 0.5524 - val_accuracy: 0.8190\n",
            "Epoch 110/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4544 - accuracy: 0.8469 - val_loss: 0.5742 - val_accuracy: 0.8196\n",
            "Epoch 111/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4438 - accuracy: 0.8513 - val_loss: 0.5223 - val_accuracy: 0.8385\n",
            "Epoch 112/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4450 - accuracy: 0.8500 - val_loss: 0.5149 - val_accuracy: 0.8368\n",
            "Epoch 113/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4416 - accuracy: 0.8532 - val_loss: 0.5267 - val_accuracy: 0.8282\n",
            "Epoch 114/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4482 - accuracy: 0.8471 - val_loss: 0.5279 - val_accuracy: 0.8351\n",
            "Epoch 115/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.8582 - val_loss: 0.5031 - val_accuracy: 0.8419\n",
            "Epoch 116/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4316 - accuracy: 0.8532 - val_loss: 0.5164 - val_accuracy: 0.8362\n",
            "Epoch 117/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4338 - accuracy: 0.8532 - val_loss: 0.4984 - val_accuracy: 0.8425\n",
            "Epoch 118/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8555 - val_loss: 0.5104 - val_accuracy: 0.8396\n",
            "Epoch 119/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.8574 - val_loss: 0.5064 - val_accuracy: 0.8408\n",
            "Epoch 120/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4234 - accuracy: 0.8511 - val_loss: 0.5047 - val_accuracy: 0.8425\n",
            "Epoch 121/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4294 - accuracy: 0.8528 - val_loss: 0.4871 - val_accuracy: 0.8431\n",
            "Epoch 122/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4016 - accuracy: 0.8639 - val_loss: 0.4824 - val_accuracy: 0.8454\n",
            "Epoch 123/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.8639 - val_loss: 0.4833 - val_accuracy: 0.8465\n",
            "Epoch 124/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8618 - val_loss: 0.4820 - val_accuracy: 0.8442\n",
            "Epoch 125/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8599 - val_loss: 0.4758 - val_accuracy: 0.8522\n",
            "Epoch 126/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8641 - val_loss: 0.4855 - val_accuracy: 0.8448\n",
            "Epoch 127/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8626 - val_loss: 0.4833 - val_accuracy: 0.8425\n",
            "Epoch 128/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8748 - val_loss: 0.4647 - val_accuracy: 0.8471\n",
            "Epoch 129/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8672 - val_loss: 0.4868 - val_accuracy: 0.8442\n",
            "Epoch 130/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3777 - accuracy: 0.8727 - val_loss: 0.4715 - val_accuracy: 0.8499\n",
            "Epoch 131/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8744 - val_loss: 0.4602 - val_accuracy: 0.8574\n",
            "Epoch 132/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3826 - accuracy: 0.8706 - val_loss: 0.4586 - val_accuracy: 0.8482\n",
            "Epoch 133/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3770 - accuracy: 0.8712 - val_loss: 0.4671 - val_accuracy: 0.8499\n",
            "Epoch 134/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3765 - accuracy: 0.8744 - val_loss: 0.4386 - val_accuracy: 0.8574\n",
            "Epoch 135/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.8687 - val_loss: 0.4442 - val_accuracy: 0.8637\n",
            "Epoch 136/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3573 - accuracy: 0.8742 - val_loss: 0.4526 - val_accuracy: 0.8551\n",
            "Epoch 137/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3689 - accuracy: 0.8712 - val_loss: 0.4470 - val_accuracy: 0.8574\n",
            "Epoch 138/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3626 - accuracy: 0.8763 - val_loss: 0.4391 - val_accuracy: 0.8551\n",
            "Epoch 139/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3748 - accuracy: 0.8752 - val_loss: 0.4239 - val_accuracy: 0.8648\n",
            "Epoch 140/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3528 - accuracy: 0.8809 - val_loss: 0.4399 - val_accuracy: 0.8637\n",
            "Epoch 141/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3611 - accuracy: 0.8752 - val_loss: 0.4312 - val_accuracy: 0.8643\n",
            "Epoch 142/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3519 - accuracy: 0.8771 - val_loss: 0.4216 - val_accuracy: 0.8620\n",
            "Epoch 143/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3642 - accuracy: 0.8778 - val_loss: 0.4273 - val_accuracy: 0.8648\n",
            "Epoch 144/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3451 - accuracy: 0.8784 - val_loss: 0.4198 - val_accuracy: 0.8654\n",
            "Epoch 145/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3519 - accuracy: 0.8757 - val_loss: 0.4162 - val_accuracy: 0.8666\n",
            "Epoch 146/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3380 - accuracy: 0.8876 - val_loss: 0.4186 - val_accuracy: 0.8700\n",
            "Epoch 147/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3416 - accuracy: 0.8786 - val_loss: 0.4034 - val_accuracy: 0.8677\n",
            "Epoch 148/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3436 - accuracy: 0.8820 - val_loss: 0.4052 - val_accuracy: 0.8723\n",
            "Epoch 149/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.8782 - val_loss: 0.4106 - val_accuracy: 0.8700\n",
            "Epoch 150/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8832 - val_loss: 0.4104 - val_accuracy: 0.8637\n",
            "Epoch 151/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8864 - val_loss: 0.4196 - val_accuracy: 0.8625\n",
            "Epoch 152/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.8939 - val_loss: 0.4028 - val_accuracy: 0.8700\n",
            "Epoch 153/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8859 - val_loss: 0.4033 - val_accuracy: 0.8688\n",
            "Epoch 154/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8899 - val_loss: 0.4059 - val_accuracy: 0.8694\n",
            "Epoch 155/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3199 - accuracy: 0.8937 - val_loss: 0.4070 - val_accuracy: 0.8694\n",
            "Epoch 156/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3205 - accuracy: 0.8912 - val_loss: 0.3990 - val_accuracy: 0.8734\n",
            "Epoch 157/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3138 - accuracy: 0.8912 - val_loss: 0.3939 - val_accuracy: 0.8706\n",
            "Epoch 158/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.8862 - val_loss: 0.3960 - val_accuracy: 0.8751\n",
            "Epoch 159/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3209 - accuracy: 0.8912 - val_loss: 0.4144 - val_accuracy: 0.8683\n",
            "Epoch 160/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3221 - accuracy: 0.8933 - val_loss: 0.3905 - val_accuracy: 0.8751\n",
            "Epoch 161/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3168 - accuracy: 0.8918 - val_loss: 0.4286 - val_accuracy: 0.8654\n",
            "Epoch 162/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3127 - accuracy: 0.8918 - val_loss: 0.3819 - val_accuracy: 0.8809\n",
            "Epoch 163/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3052 - accuracy: 0.8931 - val_loss: 0.3876 - val_accuracy: 0.8763\n",
            "Epoch 164/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3030 - accuracy: 0.8971 - val_loss: 0.3743 - val_accuracy: 0.8786\n",
            "Epoch 165/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3068 - accuracy: 0.8935 - val_loss: 0.3831 - val_accuracy: 0.8763\n",
            "Epoch 166/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2990 - accuracy: 0.8969 - val_loss: 0.3725 - val_accuracy: 0.8855\n",
            "Epoch 167/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3131 - accuracy: 0.8902 - val_loss: 0.3896 - val_accuracy: 0.8717\n",
            "Epoch 168/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2946 - accuracy: 0.9038 - val_loss: 0.3739 - val_accuracy: 0.8803\n",
            "Epoch 169/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2981 - accuracy: 0.8979 - val_loss: 0.3919 - val_accuracy: 0.8757\n",
            "Epoch 170/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2956 - accuracy: 0.8994 - val_loss: 0.3817 - val_accuracy: 0.8751\n",
            "Epoch 171/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3015 - accuracy: 0.8923 - val_loss: 0.3695 - val_accuracy: 0.8797\n",
            "Epoch 172/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2927 - accuracy: 0.8985 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 173/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2803 - accuracy: 0.9011 - val_loss: 0.3563 - val_accuracy: 0.8883\n",
            "Epoch 174/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2844 - accuracy: 0.9059 - val_loss: 0.3753 - val_accuracy: 0.8809\n",
            "Epoch 175/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2840 - accuracy: 0.8990 - val_loss: 0.3697 - val_accuracy: 0.8837\n",
            "Epoch 176/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2989 - accuracy: 0.8979 - val_loss: 0.3667 - val_accuracy: 0.8826\n",
            "Epoch 177/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2864 - accuracy: 0.8998 - val_loss: 0.3801 - val_accuracy: 0.8780\n",
            "Epoch 178/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2745 - accuracy: 0.9082 - val_loss: 0.3454 - val_accuracy: 0.8940\n",
            "Epoch 179/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2839 - accuracy: 0.9032 - val_loss: 0.3691 - val_accuracy: 0.8849\n",
            "Epoch 180/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2778 - accuracy: 0.9074 - val_loss: 0.3733 - val_accuracy: 0.8769\n",
            "Epoch 181/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2644 - accuracy: 0.9080 - val_loss: 0.3713 - val_accuracy: 0.8786\n",
            "Epoch 182/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2682 - accuracy: 0.9107 - val_loss: 0.3522 - val_accuracy: 0.8883\n",
            "Epoch 183/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2704 - accuracy: 0.9078 - val_loss: 0.3568 - val_accuracy: 0.8832\n",
            "Epoch 184/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2678 - accuracy: 0.9082 - val_loss: 0.3509 - val_accuracy: 0.8877\n",
            "Epoch 185/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2605 - accuracy: 0.9095 - val_loss: 0.3595 - val_accuracy: 0.8837\n",
            "Epoch 186/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2658 - accuracy: 0.9072 - val_loss: 0.3642 - val_accuracy: 0.8877\n",
            "Epoch 187/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2520 - accuracy: 0.9166 - val_loss: 0.3533 - val_accuracy: 0.8837\n",
            "Epoch 188/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2628 - accuracy: 0.9095 - val_loss: 0.3447 - val_accuracy: 0.8872\n",
            "Epoch 189/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2648 - accuracy: 0.9114 - val_loss: 0.3590 - val_accuracy: 0.8803\n",
            "Epoch 190/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2535 - accuracy: 0.9135 - val_loss: 0.3471 - val_accuracy: 0.8860\n",
            "Epoch 191/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2502 - accuracy: 0.9149 - val_loss: 0.3396 - val_accuracy: 0.8952\n",
            "Epoch 192/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2568 - accuracy: 0.9088 - val_loss: 0.3468 - val_accuracy: 0.8883\n",
            "Epoch 193/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2487 - accuracy: 0.9120 - val_loss: 0.3553 - val_accuracy: 0.8820\n",
            "Epoch 194/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2428 - accuracy: 0.9175 - val_loss: 0.3436 - val_accuracy: 0.8866\n",
            "Epoch 195/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2466 - accuracy: 0.9139 - val_loss: 0.3600 - val_accuracy: 0.8866\n",
            "Epoch 196/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9166 - val_loss: 0.3644 - val_accuracy: 0.8832\n",
            "Epoch 197/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2572 - accuracy: 0.9109 - val_loss: 0.3380 - val_accuracy: 0.8940\n",
            "Epoch 198/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2475 - accuracy: 0.9109 - val_loss: 0.3417 - val_accuracy: 0.8877\n",
            "Epoch 199/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2391 - accuracy: 0.9175 - val_loss: 0.3562 - val_accuracy: 0.8877\n",
            "Epoch 200/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2397 - accuracy: 0.9175 - val_loss: 0.3468 - val_accuracy: 0.8849\n",
            "Epoch 201/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2357 - accuracy: 0.9191 - val_loss: 0.3516 - val_accuracy: 0.8912\n",
            "Epoch 202/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2417 - accuracy: 0.9181 - val_loss: 0.3358 - val_accuracy: 0.8912\n",
            "Epoch 203/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9141 - val_loss: 0.3498 - val_accuracy: 0.8866\n",
            "Epoch 204/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2324 - accuracy: 0.9196 - val_loss: 0.3375 - val_accuracy: 0.8946\n",
            "Epoch 205/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2342 - accuracy: 0.9227 - val_loss: 0.3436 - val_accuracy: 0.8929\n",
            "Epoch 206/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2340 - accuracy: 0.9179 - val_loss: 0.3377 - val_accuracy: 0.8906\n",
            "Epoch 207/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2266 - accuracy: 0.9202 - val_loss: 0.3229 - val_accuracy: 0.8963\n",
            "Epoch 208/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2292 - accuracy: 0.9217 - val_loss: 0.3381 - val_accuracy: 0.8935\n",
            "Epoch 209/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2258 - accuracy: 0.9202 - val_loss: 0.3392 - val_accuracy: 0.8952\n",
            "Epoch 210/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2276 - accuracy: 0.9198 - val_loss: 0.3227 - val_accuracy: 0.8958\n",
            "Epoch 211/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2235 - accuracy: 0.9256 - val_loss: 0.3316 - val_accuracy: 0.8975\n",
            "Epoch 212/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9210 - val_loss: 0.3305 - val_accuracy: 0.8969\n",
            "Epoch 213/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2220 - accuracy: 0.9235 - val_loss: 0.3261 - val_accuracy: 0.8981\n",
            "Epoch 214/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2172 - accuracy: 0.9244 - val_loss: 0.3342 - val_accuracy: 0.8889\n",
            "Epoch 215/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2214 - accuracy: 0.9252 - val_loss: 0.3216 - val_accuracy: 0.8940\n",
            "Epoch 216/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2233 - accuracy: 0.9231 - val_loss: 0.3317 - val_accuracy: 0.8946\n",
            "Epoch 217/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2229 - accuracy: 0.9212 - val_loss: 0.3233 - val_accuracy: 0.8998\n",
            "Epoch 218/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2177 - accuracy: 0.9257 - val_loss: 0.3371 - val_accuracy: 0.8981\n",
            "Epoch 219/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2118 - accuracy: 0.9252 - val_loss: 0.3189 - val_accuracy: 0.8981\n",
            "Epoch 220/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2113 - accuracy: 0.9242 - val_loss: 0.3340 - val_accuracy: 0.8975\n",
            "Epoch 221/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2276 - accuracy: 0.9187 - val_loss: 0.3394 - val_accuracy: 0.8929\n",
            "Epoch 222/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2142 - accuracy: 0.9259 - val_loss: 0.3122 - val_accuracy: 0.9015\n",
            "Epoch 223/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2110 - accuracy: 0.9263 - val_loss: 0.3115 - val_accuracy: 0.9009\n",
            "Epoch 224/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2206 - accuracy: 0.9238 - val_loss: 0.3137 - val_accuracy: 0.8992\n",
            "Epoch 225/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1982 - accuracy: 0.9341 - val_loss: 0.3550 - val_accuracy: 0.8889\n",
            "Epoch 226/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2115 - accuracy: 0.9265 - val_loss: 0.3279 - val_accuracy: 0.8998\n",
            "Epoch 227/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9294 - val_loss: 0.3157 - val_accuracy: 0.8986\n",
            "Epoch 228/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1963 - accuracy: 0.9319 - val_loss: 0.3054 - val_accuracy: 0.9044\n",
            "Epoch 229/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2049 - accuracy: 0.9294 - val_loss: 0.3168 - val_accuracy: 0.9009\n",
            "Epoch 230/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1986 - accuracy: 0.9322 - val_loss: 0.3068 - val_accuracy: 0.9038\n",
            "Epoch 231/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9271 - val_loss: 0.3345 - val_accuracy: 0.8958\n",
            "Epoch 232/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2073 - accuracy: 0.9275 - val_loss: 0.3095 - val_accuracy: 0.9021\n",
            "Epoch 233/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9267 - val_loss: 0.3189 - val_accuracy: 0.8958\n",
            "Epoch 234/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2049 - accuracy: 0.9257 - val_loss: 0.3116 - val_accuracy: 0.8981\n",
            "Epoch 235/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1918 - accuracy: 0.9385 - val_loss: 0.3268 - val_accuracy: 0.8923\n",
            "Epoch 236/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2048 - accuracy: 0.9319 - val_loss: 0.3052 - val_accuracy: 0.9049\n",
            "Epoch 237/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1916 - accuracy: 0.9347 - val_loss: 0.3081 - val_accuracy: 0.9003\n",
            "Epoch 238/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1857 - accuracy: 0.9361 - val_loss: 0.2988 - val_accuracy: 0.9009\n",
            "Epoch 239/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1900 - accuracy: 0.9345 - val_loss: 0.3151 - val_accuracy: 0.9021\n",
            "Epoch 240/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1899 - accuracy: 0.9332 - val_loss: 0.3524 - val_accuracy: 0.8895\n",
            "Epoch 241/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1983 - accuracy: 0.9330 - val_loss: 0.3016 - val_accuracy: 0.9084\n",
            "Epoch 242/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1952 - accuracy: 0.9322 - val_loss: 0.3148 - val_accuracy: 0.9015\n",
            "Epoch 243/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1865 - accuracy: 0.9332 - val_loss: 0.3050 - val_accuracy: 0.9003\n",
            "Epoch 244/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1857 - accuracy: 0.9370 - val_loss: 0.3111 - val_accuracy: 0.9044\n",
            "Epoch 245/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1777 - accuracy: 0.9385 - val_loss: 0.3015 - val_accuracy: 0.9049\n",
            "Epoch 246/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1841 - accuracy: 0.9383 - val_loss: 0.3094 - val_accuracy: 0.9009\n",
            "Epoch 247/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9385 - val_loss: 0.2935 - val_accuracy: 0.9066\n",
            "Epoch 248/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1784 - accuracy: 0.9387 - val_loss: 0.2934 - val_accuracy: 0.9107\n",
            "Epoch 249/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1878 - accuracy: 0.9362 - val_loss: 0.3017 - val_accuracy: 0.9049\n",
            "Epoch 250/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1827 - accuracy: 0.9361 - val_loss: 0.3157 - val_accuracy: 0.9021\n",
            "Epoch 251/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9311 - val_loss: 0.3002 - val_accuracy: 0.9044\n",
            "Epoch 252/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9399 - val_loss: 0.2984 - val_accuracy: 0.9107\n",
            "Epoch 253/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1814 - accuracy: 0.9351 - val_loss: 0.3096 - val_accuracy: 0.9032\n",
            "Epoch 254/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1891 - accuracy: 0.9336 - val_loss: 0.3078 - val_accuracy: 0.9009\n",
            "Epoch 255/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9372 - val_loss: 0.3017 - val_accuracy: 0.9032\n",
            "Epoch 256/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1708 - accuracy: 0.9389 - val_loss: 0.2817 - val_accuracy: 0.9152\n",
            "Epoch 257/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9404 - val_loss: 0.2931 - val_accuracy: 0.9072\n",
            "Epoch 258/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9399 - val_loss: 0.2847 - val_accuracy: 0.9175\n",
            "Epoch 259/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1725 - accuracy: 0.9425 - val_loss: 0.3213 - val_accuracy: 0.8981\n",
            "Epoch 260/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1685 - accuracy: 0.9424 - val_loss: 0.3057 - val_accuracy: 0.9032\n",
            "Epoch 261/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1671 - accuracy: 0.9424 - val_loss: 0.2993 - val_accuracy: 0.9061\n",
            "Epoch 262/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1726 - accuracy: 0.9366 - val_loss: 0.2951 - val_accuracy: 0.9101\n",
            "Epoch 263/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1611 - accuracy: 0.9427 - val_loss: 0.2958 - val_accuracy: 0.9089\n",
            "Epoch 264/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.2899 - val_accuracy: 0.9089\n",
            "Epoch 265/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9364 - val_loss: 0.3001 - val_accuracy: 0.9044\n",
            "Epoch 266/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9410 - val_loss: 0.2945 - val_accuracy: 0.9072\n",
            "Epoch 267/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1716 - accuracy: 0.9414 - val_loss: 0.2986 - val_accuracy: 0.9061\n",
            "Epoch 268/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1679 - accuracy: 0.9406 - val_loss: 0.2887 - val_accuracy: 0.9066\n",
            "Epoch 269/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9462 - val_loss: 0.2989 - val_accuracy: 0.9066\n",
            "Epoch 270/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1640 - accuracy: 0.9443 - val_loss: 0.2816 - val_accuracy: 0.9112\n",
            "Epoch 271/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1665 - accuracy: 0.9414 - val_loss: 0.3064 - val_accuracy: 0.8946\n",
            "Epoch 272/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1646 - accuracy: 0.9445 - val_loss: 0.2890 - val_accuracy: 0.9095\n",
            "Epoch 273/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1594 - accuracy: 0.9431 - val_loss: 0.2746 - val_accuracy: 0.9181\n",
            "Epoch 274/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9429 - val_loss: 0.2820 - val_accuracy: 0.9112\n",
            "Epoch 275/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1514 - accuracy: 0.9454 - val_loss: 0.2978 - val_accuracy: 0.9055\n",
            "Epoch 276/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1515 - accuracy: 0.9490 - val_loss: 0.3324 - val_accuracy: 0.8935\n",
            "Epoch 277/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1557 - accuracy: 0.9446 - val_loss: 0.3135 - val_accuracy: 0.8963\n",
            "Epoch 278/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9429 - val_loss: 0.2953 - val_accuracy: 0.9124\n",
            "Epoch 279/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1453 - accuracy: 0.9475 - val_loss: 0.2974 - val_accuracy: 0.9095\n",
            "Epoch 280/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1567 - accuracy: 0.9477 - val_loss: 0.3179 - val_accuracy: 0.9032\n",
            "Epoch 281/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1548 - accuracy: 0.9466 - val_loss: 0.2988 - val_accuracy: 0.9072\n",
            "Epoch 282/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9416 - val_loss: 0.2981 - val_accuracy: 0.9026\n",
            "Epoch 283/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9483 - val_loss: 0.3113 - val_accuracy: 0.9055\n",
            "Epoch 284/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.9464 - val_loss: 0.2867 - val_accuracy: 0.9089\n",
            "Epoch 285/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1503 - accuracy: 0.9496 - val_loss: 0.2804 - val_accuracy: 0.9141\n",
            "Epoch 286/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1592 - accuracy: 0.9443 - val_loss: 0.2850 - val_accuracy: 0.9118\n",
            "Epoch 287/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9509 - val_loss: 0.3072 - val_accuracy: 0.9015\n",
            "Epoch 288/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1593 - accuracy: 0.9433 - val_loss: 0.2853 - val_accuracy: 0.9124\n",
            "Epoch 289/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.9477 - val_loss: 0.2980 - val_accuracy: 0.9049\n",
            "Epoch 290/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1484 - accuracy: 0.9479 - val_loss: 0.2894 - val_accuracy: 0.9044\n",
            "Epoch 291/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1455 - accuracy: 0.9506 - val_loss: 0.3194 - val_accuracy: 0.8963\n",
            "Epoch 292/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1484 - accuracy: 0.9496 - val_loss: 0.2924 - val_accuracy: 0.9072\n",
            "Epoch 293/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1496 - accuracy: 0.9485 - val_loss: 0.2996 - val_accuracy: 0.9061\n",
            "Epoch 294/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1477 - accuracy: 0.9498 - val_loss: 0.2988 - val_accuracy: 0.9072\n",
            "Epoch 295/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1488 - accuracy: 0.9519 - val_loss: 0.2891 - val_accuracy: 0.9072\n",
            "Epoch 296/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1424 - accuracy: 0.9500 - val_loss: 0.2792 - val_accuracy: 0.9112\n",
            "Epoch 297/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1539 - accuracy: 0.9479 - val_loss: 0.2869 - val_accuracy: 0.9129\n",
            "Epoch 298/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1475 - accuracy: 0.9471 - val_loss: 0.2851 - val_accuracy: 0.9107\n",
            "Epoch 299/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1437 - accuracy: 0.9498 - val_loss: 0.2812 - val_accuracy: 0.9141\n",
            "Epoch 300/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1488 - accuracy: 0.9492 - val_loss: 0.2769 - val_accuracy: 0.9170\n",
            "Epoch 301/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1527 - accuracy: 0.9443 - val_loss: 0.2688 - val_accuracy: 0.9187\n",
            "Epoch 302/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1404 - accuracy: 0.9500 - val_loss: 0.3139 - val_accuracy: 0.9038\n",
            "Epoch 303/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 0.2845 - val_accuracy: 0.9118\n",
            "Epoch 304/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1435 - accuracy: 0.9506 - val_loss: 0.2866 - val_accuracy: 0.9089\n",
            "Epoch 305/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9542 - val_loss: 0.2783 - val_accuracy: 0.9101\n",
            "Epoch 306/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1347 - accuracy: 0.9519 - val_loss: 0.2892 - val_accuracy: 0.9095\n",
            "Epoch 307/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1363 - accuracy: 0.9527 - val_loss: 0.2727 - val_accuracy: 0.9124\n",
            "Epoch 308/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1393 - accuracy: 0.9553 - val_loss: 0.3001 - val_accuracy: 0.9124\n",
            "Epoch 309/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9561 - val_loss: 0.2787 - val_accuracy: 0.9158\n",
            "Epoch 310/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9576 - val_loss: 0.2867 - val_accuracy: 0.9124\n",
            "Epoch 311/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1434 - accuracy: 0.9496 - val_loss: 0.2807 - val_accuracy: 0.9152\n",
            "Epoch 312/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1339 - accuracy: 0.9542 - val_loss: 0.2967 - val_accuracy: 0.9061\n",
            "Epoch 313/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1390 - accuracy: 0.9513 - val_loss: 0.2824 - val_accuracy: 0.9141\n",
            "Epoch 314/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1384 - accuracy: 0.9477 - val_loss: 0.2863 - val_accuracy: 0.9135\n",
            "Epoch 315/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1467 - accuracy: 0.9523 - val_loss: 0.2883 - val_accuracy: 0.9129\n",
            "Epoch 316/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1328 - accuracy: 0.9534 - val_loss: 0.2922 - val_accuracy: 0.9112\n",
            "Epoch 317/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9530 - val_loss: 0.2909 - val_accuracy: 0.9078\n",
            "Epoch 318/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1409 - accuracy: 0.9502 - val_loss: 0.2719 - val_accuracy: 0.9141\n",
            "Epoch 319/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1404 - accuracy: 0.9508 - val_loss: 0.2929 - val_accuracy: 0.9072\n",
            "Epoch 320/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1357 - accuracy: 0.9538 - val_loss: 0.2773 - val_accuracy: 0.9124\n",
            "Epoch 321/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1274 - accuracy: 0.9580 - val_loss: 0.2739 - val_accuracy: 0.9141\n",
            "Epoch 322/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9527 - val_loss: 0.2920 - val_accuracy: 0.9061\n",
            "Epoch 323/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9561 - val_loss: 0.2965 - val_accuracy: 0.9066\n",
            "Epoch 324/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1234 - accuracy: 0.9574 - val_loss: 0.2881 - val_accuracy: 0.9147\n",
            "Epoch 325/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1288 - accuracy: 0.9572 - val_loss: 0.3057 - val_accuracy: 0.9038\n",
            "Epoch 326/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1243 - accuracy: 0.9576 - val_loss: 0.2758 - val_accuracy: 0.9158\n",
            "Epoch 327/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9553 - val_loss: 0.2745 - val_accuracy: 0.9112\n",
            "Epoch 328/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1265 - accuracy: 0.9586 - val_loss: 0.2940 - val_accuracy: 0.9129\n",
            "Epoch 329/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1197 - accuracy: 0.9601 - val_loss: 0.2834 - val_accuracy: 0.9129\n",
            "Epoch 330/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.9616 - val_loss: 0.2666 - val_accuracy: 0.9152\n",
            "Epoch 331/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1298 - accuracy: 0.9544 - val_loss: 0.2926 - val_accuracy: 0.9129\n",
            "Epoch 332/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1308 - accuracy: 0.9593 - val_loss: 0.2663 - val_accuracy: 0.9164\n",
            "Epoch 333/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1281 - accuracy: 0.9550 - val_loss: 0.2604 - val_accuracy: 0.9198\n",
            "Epoch 334/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.9603 - val_loss: 0.2778 - val_accuracy: 0.9112\n",
            "Epoch 335/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9599 - val_loss: 0.2821 - val_accuracy: 0.9118\n",
            "Epoch 336/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1126 - accuracy: 0.9624 - val_loss: 0.2842 - val_accuracy: 0.9112\n",
            "Epoch 337/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9609 - val_loss: 0.2770 - val_accuracy: 0.9181\n",
            "Epoch 338/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1242 - accuracy: 0.9542 - val_loss: 0.2900 - val_accuracy: 0.9107\n",
            "Epoch 339/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1215 - accuracy: 0.9572 - val_loss: 0.2833 - val_accuracy: 0.9084\n",
            "Epoch 340/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1173 - accuracy: 0.9595 - val_loss: 0.2789 - val_accuracy: 0.9164\n",
            "Epoch 341/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9563 - val_loss: 0.2707 - val_accuracy: 0.9181\n",
            "Epoch 342/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9622 - val_loss: 0.2708 - val_accuracy: 0.9147\n",
            "Epoch 343/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1231 - accuracy: 0.9607 - val_loss: 0.2752 - val_accuracy: 0.9107\n",
            "Epoch 344/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9563 - val_loss: 0.2993 - val_accuracy: 0.9078\n",
            "Epoch 345/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1346 - accuracy: 0.9523 - val_loss: 0.2741 - val_accuracy: 0.9181\n",
            "Epoch 346/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9609 - val_loss: 0.2649 - val_accuracy: 0.9181\n",
            "Epoch 347/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1300 - accuracy: 0.9563 - val_loss: 0.2795 - val_accuracy: 0.9158\n",
            "Epoch 348/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9632 - val_loss: 0.2776 - val_accuracy: 0.9101\n",
            "Epoch 349/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1279 - accuracy: 0.9593 - val_loss: 0.2835 - val_accuracy: 0.9101\n",
            "Epoch 350/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1239 - accuracy: 0.9578 - val_loss: 0.2940 - val_accuracy: 0.9124\n",
            "Epoch 351/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1239 - accuracy: 0.9548 - val_loss: 0.2819 - val_accuracy: 0.9175\n",
            "Epoch 352/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1229 - accuracy: 0.9569 - val_loss: 0.2620 - val_accuracy: 0.9204\n",
            "Epoch 353/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.9655 - val_loss: 0.2742 - val_accuracy: 0.9152\n",
            "Epoch 354/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.9624 - val_loss: 0.2926 - val_accuracy: 0.9107\n",
            "Epoch 355/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1089 - accuracy: 0.9614 - val_loss: 0.2743 - val_accuracy: 0.9158\n",
            "Epoch 356/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1060 - accuracy: 0.9637 - val_loss: 0.2671 - val_accuracy: 0.9221\n",
            "Epoch 357/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1040 - accuracy: 0.9653 - val_loss: 0.2835 - val_accuracy: 0.9112\n",
            "Epoch 358/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.9611 - val_loss: 0.2769 - val_accuracy: 0.9170\n",
            "Epoch 359/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1097 - accuracy: 0.9588 - val_loss: 0.2801 - val_accuracy: 0.9112\n",
            "Epoch 360/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1124 - accuracy: 0.9607 - val_loss: 0.2589 - val_accuracy: 0.9215\n",
            "Epoch 361/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1074 - accuracy: 0.9634 - val_loss: 0.2652 - val_accuracy: 0.9192\n",
            "Epoch 362/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9576 - val_loss: 0.2723 - val_accuracy: 0.9164\n",
            "Epoch 363/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9597 - val_loss: 0.2598 - val_accuracy: 0.9192\n",
            "Epoch 364/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9634 - val_loss: 0.2671 - val_accuracy: 0.9164\n",
            "Epoch 365/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9576 - val_loss: 0.2659 - val_accuracy: 0.9192\n",
            "Epoch 366/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1067 - accuracy: 0.9634 - val_loss: 0.2610 - val_accuracy: 0.9181\n",
            "Epoch 367/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9620 - val_loss: 0.2786 - val_accuracy: 0.9135\n",
            "Epoch 368/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9632 - val_loss: 0.2856 - val_accuracy: 0.9124\n",
            "Epoch 369/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9655 - val_loss: 0.2757 - val_accuracy: 0.9170\n",
            "Epoch 370/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1068 - accuracy: 0.9641 - val_loss: 0.2657 - val_accuracy: 0.9204\n",
            "Epoch 371/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1071 - accuracy: 0.9645 - val_loss: 0.2677 - val_accuracy: 0.9141\n",
            "Epoch 372/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9624 - val_loss: 0.2693 - val_accuracy: 0.9147\n",
            "Epoch 373/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9614 - val_loss: 0.2814 - val_accuracy: 0.9124\n",
            "Epoch 374/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9599 - val_loss: 0.2655 - val_accuracy: 0.9204\n",
            "Epoch 375/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1054 - accuracy: 0.9634 - val_loss: 0.2675 - val_accuracy: 0.9141\n",
            "Epoch 376/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9603 - val_loss: 0.2739 - val_accuracy: 0.9181\n",
            "Epoch 377/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1157 - accuracy: 0.9601 - val_loss: 0.2509 - val_accuracy: 0.9273\n",
            "Epoch 378/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0994 - accuracy: 0.9645 - val_loss: 0.2687 - val_accuracy: 0.9158\n",
            "Epoch 379/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1055 - accuracy: 0.9645 - val_loss: 0.2609 - val_accuracy: 0.9192\n",
            "Epoch 380/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1010 - accuracy: 0.9641 - val_loss: 0.2674 - val_accuracy: 0.9164\n",
            "Epoch 381/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9651 - val_loss: 0.2755 - val_accuracy: 0.9170\n",
            "Epoch 382/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9605 - val_loss: 0.2550 - val_accuracy: 0.9181\n",
            "Epoch 383/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0986 - accuracy: 0.9672 - val_loss: 0.2703 - val_accuracy: 0.9187\n",
            "Epoch 384/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9630 - val_loss: 0.2613 - val_accuracy: 0.9192\n",
            "Epoch 385/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1075 - accuracy: 0.9649 - val_loss: 0.2584 - val_accuracy: 0.9215\n",
            "Epoch 386/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9672 - val_loss: 0.2528 - val_accuracy: 0.9233\n",
            "Epoch 387/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9670 - val_loss: 0.2674 - val_accuracy: 0.9204\n",
            "Epoch 388/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9651 - val_loss: 0.2595 - val_accuracy: 0.9227\n",
            "Epoch 389/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9647 - val_loss: 0.2687 - val_accuracy: 0.9204\n",
            "Epoch 390/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1007 - accuracy: 0.9635 - val_loss: 0.2585 - val_accuracy: 0.9215\n",
            "Epoch 391/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0930 - accuracy: 0.9710 - val_loss: 0.2821 - val_accuracy: 0.9198\n",
            "Epoch 392/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.9668 - val_loss: 0.2725 - val_accuracy: 0.9175\n",
            "Epoch 393/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9718 - val_loss: 0.2554 - val_accuracy: 0.9210\n",
            "Epoch 394/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9641 - val_loss: 0.2645 - val_accuracy: 0.9210\n",
            "Epoch 395/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9628 - val_loss: 0.2700 - val_accuracy: 0.9170\n",
            "Epoch 396/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9639 - val_loss: 0.2673 - val_accuracy: 0.9187\n",
            "Epoch 397/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9664 - val_loss: 0.2637 - val_accuracy: 0.9192\n",
            "Epoch 398/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9643 - val_loss: 0.2503 - val_accuracy: 0.9221\n",
            "Epoch 399/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0975 - accuracy: 0.9658 - val_loss: 0.2627 - val_accuracy: 0.9198\n",
            "Epoch 400/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0954 - accuracy: 0.9658 - val_loss: 0.2716 - val_accuracy: 0.9187\n",
            "Epoch 401/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0865 - accuracy: 0.9697 - val_loss: 0.2745 - val_accuracy: 0.9164\n",
            "Epoch 402/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.1033 - accuracy: 0.9662 - val_loss: 0.2692 - val_accuracy: 0.9221\n",
            "Epoch 403/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1075 - accuracy: 0.9609 - val_loss: 0.2701 - val_accuracy: 0.9215\n",
            "Epoch 404/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 0.2588 - val_accuracy: 0.9181\n",
            "Epoch 405/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0970 - accuracy: 0.9655 - val_loss: 0.2618 - val_accuracy: 0.9192\n",
            "Epoch 406/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9689 - val_loss: 0.2666 - val_accuracy: 0.9181\n",
            "Epoch 407/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0934 - accuracy: 0.9693 - val_loss: 0.2626 - val_accuracy: 0.9187\n",
            "Epoch 408/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0899 - accuracy: 0.9698 - val_loss: 0.2692 - val_accuracy: 0.9192\n",
            "Epoch 409/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9651 - val_loss: 0.2747 - val_accuracy: 0.9170\n",
            "Epoch 410/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0920 - accuracy: 0.9695 - val_loss: 0.2724 - val_accuracy: 0.9215\n",
            "Epoch 411/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9656 - val_loss: 0.2828 - val_accuracy: 0.9129\n",
            "Epoch 412/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9664 - val_loss: 0.2934 - val_accuracy: 0.9141\n",
            "Epoch 413/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9655 - val_loss: 0.2763 - val_accuracy: 0.9158\n",
            "Epoch 414/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9708 - val_loss: 0.2861 - val_accuracy: 0.9152\n",
            "Epoch 415/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9693 - val_loss: 0.2649 - val_accuracy: 0.9215\n",
            "Epoch 416/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9674 - val_loss: 0.2659 - val_accuracy: 0.9170\n",
            "Epoch 417/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9681 - val_loss: 0.2690 - val_accuracy: 0.9204\n",
            "Epoch 418/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0876 - accuracy: 0.9695 - val_loss: 0.2768 - val_accuracy: 0.9204\n",
            "Epoch 419/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9708 - val_loss: 0.2615 - val_accuracy: 0.9238\n",
            "Epoch 420/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0997 - accuracy: 0.9662 - val_loss: 0.2692 - val_accuracy: 0.9135\n",
            "Epoch 421/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0935 - accuracy: 0.9679 - val_loss: 0.2639 - val_accuracy: 0.9192\n",
            "Epoch 422/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0930 - accuracy: 0.9656 - val_loss: 0.2638 - val_accuracy: 0.9227\n",
            "Epoch 423/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0910 - accuracy: 0.9660 - val_loss: 0.2622 - val_accuracy: 0.9261\n",
            "Epoch 424/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.2665 - val_accuracy: 0.9158\n",
            "Epoch 425/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0967 - accuracy: 0.9674 - val_loss: 0.2708 - val_accuracy: 0.9187\n",
            "Epoch 426/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 0.2681 - val_accuracy: 0.9187\n",
            "Epoch 427/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9691 - val_loss: 0.2606 - val_accuracy: 0.9227\n",
            "Epoch 428/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0923 - accuracy: 0.9666 - val_loss: 0.2656 - val_accuracy: 0.9187\n",
            "Epoch 429/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9676 - val_loss: 0.2803 - val_accuracy: 0.9124\n",
            "Epoch 430/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9698 - val_loss: 0.2833 - val_accuracy: 0.9141\n",
            "Epoch 431/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0974 - accuracy: 0.9662 - val_loss: 0.2591 - val_accuracy: 0.9181\n",
            "Epoch 432/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0855 - accuracy: 0.9683 - val_loss: 0.2521 - val_accuracy: 0.9221\n",
            "Epoch 433/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0924 - accuracy: 0.9697 - val_loss: 0.2632 - val_accuracy: 0.9215\n",
            "Epoch 434/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0869 - accuracy: 0.9719 - val_loss: 0.2604 - val_accuracy: 0.9204\n",
            "Epoch 435/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0887 - accuracy: 0.9685 - val_loss: 0.2566 - val_accuracy: 0.9255\n",
            "Epoch 436/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0901 - accuracy: 0.9704 - val_loss: 0.2610 - val_accuracy: 0.9244\n",
            "Epoch 437/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0793 - accuracy: 0.9723 - val_loss: 0.2714 - val_accuracy: 0.9170\n",
            "Epoch 438/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0822 - accuracy: 0.9704 - val_loss: 0.2688 - val_accuracy: 0.9233\n",
            "Epoch 439/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9695 - val_loss: 0.2483 - val_accuracy: 0.9233\n",
            "Epoch 440/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9700 - val_loss: 0.2526 - val_accuracy: 0.9215\n",
            "Epoch 441/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0787 - accuracy: 0.9737 - val_loss: 0.2612 - val_accuracy: 0.9255\n",
            "Epoch 442/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9725 - val_loss: 0.2505 - val_accuracy: 0.9255\n",
            "Epoch 443/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0890 - accuracy: 0.9689 - val_loss: 0.2675 - val_accuracy: 0.9181\n",
            "Epoch 444/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0828 - accuracy: 0.9719 - val_loss: 0.2710 - val_accuracy: 0.9192\n",
            "Epoch 445/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9729 - val_loss: 0.2666 - val_accuracy: 0.9192\n",
            "Epoch 446/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 0.2790 - val_accuracy: 0.9233\n",
            "Epoch 447/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0870 - accuracy: 0.9719 - val_loss: 0.2651 - val_accuracy: 0.9204\n",
            "Epoch 448/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.2546 - val_accuracy: 0.9238\n",
            "Epoch 449/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9752 - val_loss: 0.2571 - val_accuracy: 0.9204\n",
            "Epoch 450/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0755 - accuracy: 0.9767 - val_loss: 0.2594 - val_accuracy: 0.9204\n",
            "Epoch 451/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0798 - accuracy: 0.9725 - val_loss: 0.2714 - val_accuracy: 0.9227\n",
            "Epoch 452/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9695 - val_loss: 0.2782 - val_accuracy: 0.9198\n",
            "Epoch 453/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0802 - accuracy: 0.9735 - val_loss: 0.2713 - val_accuracy: 0.9170\n",
            "Epoch 454/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9735 - val_loss: 0.2601 - val_accuracy: 0.9267\n",
            "Epoch 455/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0851 - accuracy: 0.9708 - val_loss: 0.2510 - val_accuracy: 0.9233\n",
            "Epoch 456/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0725 - accuracy: 0.9748 - val_loss: 0.2486 - val_accuracy: 0.9221\n",
            "Epoch 457/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0903 - accuracy: 0.9679 - val_loss: 0.2645 - val_accuracy: 0.9238\n",
            "Epoch 458/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0764 - accuracy: 0.9725 - val_loss: 0.2726 - val_accuracy: 0.9147\n",
            "Epoch 459/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0803 - accuracy: 0.9719 - val_loss: 0.2758 - val_accuracy: 0.9181\n",
            "Epoch 460/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9721 - val_loss: 0.2626 - val_accuracy: 0.9238\n",
            "Epoch 461/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9733 - val_loss: 0.2576 - val_accuracy: 0.9215\n",
            "Epoch 462/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0770 - accuracy: 0.9733 - val_loss: 0.2556 - val_accuracy: 0.9250\n",
            "Epoch 463/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0779 - accuracy: 0.9710 - val_loss: 0.2496 - val_accuracy: 0.9210\n",
            "Epoch 464/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0831 - accuracy: 0.9721 - val_loss: 0.2563 - val_accuracy: 0.9227\n",
            "Epoch 465/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0926 - accuracy: 0.9689 - val_loss: 0.2701 - val_accuracy: 0.9198\n",
            "Epoch 466/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0747 - accuracy: 0.9742 - val_loss: 0.2500 - val_accuracy: 0.9198\n",
            "Epoch 467/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0700 - accuracy: 0.9773 - val_loss: 0.2646 - val_accuracy: 0.9215\n",
            "Epoch 468/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 0.2658 - val_accuracy: 0.9198\n",
            "Epoch 469/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 0.2609 - val_accuracy: 0.9261\n",
            "Epoch 470/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0815 - accuracy: 0.9721 - val_loss: 0.2507 - val_accuracy: 0.9267\n",
            "Epoch 471/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.2470 - val_accuracy: 0.9221\n",
            "Epoch 472/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0754 - accuracy: 0.9731 - val_loss: 0.2635 - val_accuracy: 0.9250\n",
            "Epoch 473/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0790 - accuracy: 0.9710 - val_loss: 0.2620 - val_accuracy: 0.9296\n",
            "Epoch 474/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: 0.2651 - val_accuracy: 0.9233\n",
            "Epoch 475/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9735 - val_loss: 0.2556 - val_accuracy: 0.9244\n",
            "Epoch 476/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0747 - accuracy: 0.9740 - val_loss: 0.2524 - val_accuracy: 0.9221\n",
            "Epoch 477/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9752 - val_loss: 0.2681 - val_accuracy: 0.9238\n",
            "Epoch 478/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9712 - val_loss: 0.2628 - val_accuracy: 0.9227\n",
            "Epoch 479/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9737 - val_loss: 0.2748 - val_accuracy: 0.9227\n",
            "Epoch 480/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.2649 - val_accuracy: 0.9267\n",
            "Epoch 481/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9756 - val_loss: 0.2553 - val_accuracy: 0.9290\n",
            "Epoch 482/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9754 - val_loss: 0.2527 - val_accuracy: 0.9227\n",
            "Epoch 483/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9756 - val_loss: 0.2713 - val_accuracy: 0.9250\n",
            "Epoch 484/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 0.2555 - val_accuracy: 0.9227\n",
            "Epoch 485/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0783 - accuracy: 0.9733 - val_loss: 0.2610 - val_accuracy: 0.9198\n",
            "Epoch 486/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0782 - accuracy: 0.9742 - val_loss: 0.2694 - val_accuracy: 0.9210\n",
            "Epoch 487/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0740 - accuracy: 0.9737 - val_loss: 0.2674 - val_accuracy: 0.9244\n",
            "Epoch 488/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 0.2591 - val_accuracy: 0.9244\n",
            "Epoch 489/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9759 - val_loss: 0.2451 - val_accuracy: 0.9301\n",
            "Epoch 490/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0834 - accuracy: 0.9729 - val_loss: 0.2727 - val_accuracy: 0.9181\n",
            "Epoch 491/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0709 - accuracy: 0.9782 - val_loss: 0.2586 - val_accuracy: 0.9244\n",
            "Epoch 492/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0742 - accuracy: 0.9758 - val_loss: 0.2601 - val_accuracy: 0.9301\n",
            "Epoch 493/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9773 - val_loss: 0.2555 - val_accuracy: 0.9244\n",
            "Epoch 494/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9777 - val_loss: 0.2461 - val_accuracy: 0.9267\n",
            "Epoch 495/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0696 - accuracy: 0.9773 - val_loss: 0.2760 - val_accuracy: 0.9187\n",
            "Epoch 496/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9800 - val_loss: 0.2645 - val_accuracy: 0.9221\n",
            "Epoch 497/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.2617 - val_accuracy: 0.9250\n",
            "Epoch 498/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.9756 - val_loss: 0.2621 - val_accuracy: 0.9210\n",
            "Epoch 499/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9729 - val_loss: 0.2465 - val_accuracy: 0.9273\n",
            "Epoch 500/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0691 - accuracy: 0.9784 - val_loss: 0.2568 - val_accuracy: 0.9233\n",
            "Epoch 501/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 0.9786 - val_loss: 0.2735 - val_accuracy: 0.9261\n",
            "Epoch 502/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0716 - accuracy: 0.9777 - val_loss: 0.2708 - val_accuracy: 0.9221\n",
            "Epoch 503/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 0.2810 - val_accuracy: 0.9233\n",
            "Epoch 504/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0704 - accuracy: 0.9769 - val_loss: 0.2732 - val_accuracy: 0.9215\n",
            "Epoch 505/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0711 - accuracy: 0.9742 - val_loss: 0.2567 - val_accuracy: 0.9244\n",
            "Epoch 506/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0708 - accuracy: 0.9769 - val_loss: 0.2599 - val_accuracy: 0.9233\n",
            "Epoch 507/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0664 - accuracy: 0.9777 - val_loss: 0.2534 - val_accuracy: 0.9273\n",
            "Epoch 508/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0737 - accuracy: 0.9746 - val_loss: 0.2624 - val_accuracy: 0.9238\n",
            "Epoch 509/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.2631 - val_accuracy: 0.9238\n",
            "Epoch 510/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 0.9748 - val_loss: 0.2684 - val_accuracy: 0.9250\n",
            "Epoch 511/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9752 - val_loss: 0.2726 - val_accuracy: 0.9261\n",
            "Epoch 512/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9746 - val_loss: 0.2714 - val_accuracy: 0.9204\n",
            "Epoch 513/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9773 - val_loss: 0.2828 - val_accuracy: 0.9198\n",
            "Epoch 514/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9813 - val_loss: 0.2635 - val_accuracy: 0.9233\n",
            "Epoch 515/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0640 - accuracy: 0.9792 - val_loss: 0.2761 - val_accuracy: 0.9227\n",
            "Epoch 516/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9786 - val_loss: 0.2660 - val_accuracy: 0.9267\n",
            "Epoch 517/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 0.9796 - val_loss: 0.2656 - val_accuracy: 0.9221\n",
            "Epoch 518/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9752 - val_loss: 0.2746 - val_accuracy: 0.9198\n",
            "Epoch 519/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 0.9761 - val_loss: 0.2668 - val_accuracy: 0.9284\n",
            "Epoch 520/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0630 - accuracy: 0.9788 - val_loss: 0.2645 - val_accuracy: 0.9221\n",
            "Epoch 521/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9727 - val_loss: 0.2731 - val_accuracy: 0.9175\n",
            "Epoch 522/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.2564 - val_accuracy: 0.9261\n",
            "Epoch 523/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 0.9754 - val_loss: 0.2795 - val_accuracy: 0.9244\n",
            "Epoch 524/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.2660 - val_accuracy: 0.9244\n",
            "Epoch 525/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9733 - val_loss: 0.2712 - val_accuracy: 0.9273\n",
            "Epoch 526/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0700 - accuracy: 0.9759 - val_loss: 0.2739 - val_accuracy: 0.9221\n",
            "Epoch 527/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0747 - accuracy: 0.9758 - val_loss: 0.2563 - val_accuracy: 0.9278\n",
            "Epoch 528/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0615 - accuracy: 0.9801 - val_loss: 0.2636 - val_accuracy: 0.9227\n",
            "Epoch 529/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 0.2859 - val_accuracy: 0.9158\n",
            "Epoch 530/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9771 - val_loss: 0.2617 - val_accuracy: 0.9238\n",
            "Epoch 531/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0709 - accuracy: 0.9758 - val_loss: 0.2626 - val_accuracy: 0.9261\n",
            "Epoch 532/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9763 - val_loss: 0.2595 - val_accuracy: 0.9255\n",
            "Epoch 533/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0656 - accuracy: 0.9761 - val_loss: 0.2607 - val_accuracy: 0.9301\n",
            "Epoch 534/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 0.9771 - val_loss: 0.2918 - val_accuracy: 0.9152\n",
            "Epoch 535/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9775 - val_loss: 0.2714 - val_accuracy: 0.9238\n",
            "Epoch 536/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0716 - accuracy: 0.9727 - val_loss: 0.2686 - val_accuracy: 0.9210\n",
            "Epoch 537/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0590 - accuracy: 0.9801 - val_loss: 0.2737 - val_accuracy: 0.9255\n",
            "Epoch 538/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9754 - val_loss: 0.2683 - val_accuracy: 0.9227\n",
            "Epoch 539/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.2782 - val_accuracy: 0.9181\n",
            "Epoch 540/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.2679 - val_accuracy: 0.9250\n",
            "Epoch 541/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 0.2763 - val_accuracy: 0.9192\n",
            "Epoch 542/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.2706 - val_accuracy: 0.9204\n",
            "Epoch 543/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.2763 - val_accuracy: 0.9204\n",
            "Epoch 544/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 0.2565 - val_accuracy: 0.9284\n",
            "Epoch 545/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.2699 - val_accuracy: 0.9250\n",
            "Epoch 546/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.2657 - val_accuracy: 0.9244\n",
            "Epoch 547/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0632 - accuracy: 0.9796 - val_loss: 0.2908 - val_accuracy: 0.9244\n",
            "Epoch 548/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0685 - accuracy: 0.9790 - val_loss: 0.2631 - val_accuracy: 0.9267\n",
            "Epoch 549/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0595 - accuracy: 0.9796 - val_loss: 0.2682 - val_accuracy: 0.9233\n",
            "Epoch 550/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0592 - accuracy: 0.9807 - val_loss: 0.2623 - val_accuracy: 0.9301\n",
            "Epoch 551/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0665 - accuracy: 0.9773 - val_loss: 0.2702 - val_accuracy: 0.9255\n",
            "Epoch 552/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0562 - accuracy: 0.9830 - val_loss: 0.2908 - val_accuracy: 0.9238\n",
            "Epoch 553/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0620 - accuracy: 0.9794 - val_loss: 0.2621 - val_accuracy: 0.9284\n",
            "Epoch 554/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.2695 - val_accuracy: 0.9244\n",
            "Epoch 555/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.2678 - val_accuracy: 0.9296\n",
            "Epoch 556/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0590 - accuracy: 0.9813 - val_loss: 0.2597 - val_accuracy: 0.9307\n",
            "Epoch 557/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 0.9780 - val_loss: 0.2670 - val_accuracy: 0.9250\n",
            "Epoch 558/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0608 - accuracy: 0.9790 - val_loss: 0.2696 - val_accuracy: 0.9301\n",
            "Epoch 559/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0581 - accuracy: 0.9807 - val_loss: 0.2831 - val_accuracy: 0.9227\n",
            "Epoch 560/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9771 - val_loss: 0.2863 - val_accuracy: 0.9267\n",
            "Epoch 561/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 0.2829 - val_accuracy: 0.9261\n",
            "Epoch 562/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 0.9782 - val_loss: 0.2757 - val_accuracy: 0.9238\n",
            "Epoch 563/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 0.9765 - val_loss: 0.2620 - val_accuracy: 0.9261\n",
            "Epoch 564/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0623 - accuracy: 0.9813 - val_loss: 0.2647 - val_accuracy: 0.9284\n",
            "Epoch 565/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 0.9769 - val_loss: 0.2678 - val_accuracy: 0.9318\n",
            "Epoch 566/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0654 - accuracy: 0.9790 - val_loss: 0.2655 - val_accuracy: 0.9255\n",
            "Epoch 567/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 0.9794 - val_loss: 0.2711 - val_accuracy: 0.9244\n",
            "Epoch 568/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.2659 - val_accuracy: 0.9301\n",
            "Epoch 569/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0606 - accuracy: 0.9779 - val_loss: 0.2703 - val_accuracy: 0.9261\n",
            "Epoch 570/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.2716 - val_accuracy: 0.9278\n",
            "Epoch 571/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 0.2755 - val_accuracy: 0.9244\n",
            "Epoch 572/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.2524 - val_accuracy: 0.9313\n",
            "Epoch 573/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0596 - accuracy: 0.9777 - val_loss: 0.2688 - val_accuracy: 0.9255\n",
            "Epoch 574/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9851 - val_loss: 0.2800 - val_accuracy: 0.9273\n",
            "Epoch 575/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0577 - accuracy: 0.9805 - val_loss: 0.2756 - val_accuracy: 0.9244\n",
            "Epoch 576/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0596 - accuracy: 0.9779 - val_loss: 0.2729 - val_accuracy: 0.9290\n",
            "Epoch 577/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0608 - accuracy: 0.9792 - val_loss: 0.2793 - val_accuracy: 0.9215\n",
            "Epoch 578/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9817 - val_loss: 0.2773 - val_accuracy: 0.9267\n",
            "Epoch 579/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 0.9796 - val_loss: 0.2627 - val_accuracy: 0.9261\n",
            "Epoch 580/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9824 - val_loss: 0.2690 - val_accuracy: 0.9313\n",
            "Epoch 581/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0605 - accuracy: 0.9786 - val_loss: 0.2871 - val_accuracy: 0.9244\n",
            "Epoch 582/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9758 - val_loss: 0.2743 - val_accuracy: 0.9278\n",
            "Epoch 583/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 0.9801 - val_loss: 0.2933 - val_accuracy: 0.9158\n",
            "Epoch 584/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9786 - val_loss: 0.2641 - val_accuracy: 0.9250\n",
            "Epoch 585/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0585 - accuracy: 0.9790 - val_loss: 0.2569 - val_accuracy: 0.9301\n",
            "Epoch 586/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.2762 - val_accuracy: 0.9233\n",
            "Epoch 587/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0610 - accuracy: 0.9807 - val_loss: 0.2816 - val_accuracy: 0.9278\n",
            "Epoch 588/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0554 - accuracy: 0.9842 - val_loss: 0.2820 - val_accuracy: 0.9221\n",
            "Epoch 589/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.2714 - val_accuracy: 0.9221\n",
            "Epoch 590/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9800 - val_loss: 0.2708 - val_accuracy: 0.9290\n",
            "Epoch 591/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9809 - val_loss: 0.2674 - val_accuracy: 0.9336\n",
            "Epoch 592/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.2827 - val_accuracy: 0.9255\n",
            "Epoch 593/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0582 - accuracy: 0.9819 - val_loss: 0.2892 - val_accuracy: 0.9238\n",
            "Epoch 594/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0495 - accuracy: 0.9822 - val_loss: 0.2822 - val_accuracy: 0.9290\n",
            "Epoch 595/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 0.2751 - val_accuracy: 0.9313\n",
            "Epoch 596/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9801 - val_loss: 0.2919 - val_accuracy: 0.9215\n",
            "Epoch 597/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0550 - accuracy: 0.9840 - val_loss: 0.2690 - val_accuracy: 0.9255\n",
            "Epoch 598/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9813 - val_loss: 0.2769 - val_accuracy: 0.9255\n",
            "Epoch 599/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0552 - accuracy: 0.9821 - val_loss: 0.2935 - val_accuracy: 0.9238\n",
            "Epoch 600/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.2719 - val_accuracy: 0.9301\n",
            "Epoch 601/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0566 - accuracy: 0.9840 - val_loss: 0.2771 - val_accuracy: 0.9273\n",
            "Epoch 602/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.2768 - val_accuracy: 0.9284\n",
            "Epoch 603/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.2745 - val_accuracy: 0.9301\n",
            "Epoch 604/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0539 - accuracy: 0.9813 - val_loss: 0.2658 - val_accuracy: 0.9238\n",
            "Epoch 605/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0564 - accuracy: 0.9826 - val_loss: 0.2809 - val_accuracy: 0.9255\n",
            "Epoch 606/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9807 - val_loss: 0.2883 - val_accuracy: 0.9227\n",
            "Epoch 607/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.2983 - val_accuracy: 0.9267\n",
            "Epoch 608/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9782 - val_loss: 0.3119 - val_accuracy: 0.9198\n",
            "Epoch 609/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 0.2890 - val_accuracy: 0.9238\n",
            "Epoch 610/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9796 - val_loss: 0.2750 - val_accuracy: 0.9301\n",
            "Epoch 611/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9845 - val_loss: 0.2814 - val_accuracy: 0.9284\n",
            "Epoch 612/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0551 - accuracy: 0.9838 - val_loss: 0.2784 - val_accuracy: 0.9250\n",
            "Epoch 613/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 0.2882 - val_accuracy: 0.9273\n",
            "Epoch 614/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 0.2714 - val_accuracy: 0.9273\n",
            "Epoch 615/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9834 - val_loss: 0.2696 - val_accuracy: 0.9273\n",
            "Epoch 616/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0473 - accuracy: 0.9866 - val_loss: 0.2859 - val_accuracy: 0.9255\n",
            "Epoch 617/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 0.2768 - val_accuracy: 0.9273\n",
            "Epoch 618/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 0.2757 - val_accuracy: 0.9244\n",
            "Epoch 619/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0552 - accuracy: 0.9801 - val_loss: 0.2673 - val_accuracy: 0.9318\n",
            "Epoch 620/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.2668 - val_accuracy: 0.9278\n",
            "Epoch 621/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.2746 - val_accuracy: 0.9221\n",
            "Epoch 622/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 0.2895 - val_accuracy: 0.9244\n",
            "Epoch 623/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.2580 - val_accuracy: 0.9290\n",
            "Epoch 624/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.2759 - val_accuracy: 0.9261\n",
            "Epoch 625/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9780 - val_loss: 0.2711 - val_accuracy: 0.9284\n",
            "Epoch 626/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.2697 - val_accuracy: 0.9284\n",
            "Epoch 627/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.2716 - val_accuracy: 0.9255\n",
            "Epoch 628/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 0.9786 - val_loss: 0.2760 - val_accuracy: 0.9267\n",
            "Epoch 629/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9826 - val_loss: 0.2752 - val_accuracy: 0.9255\n",
            "Epoch 630/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9822 - val_loss: 0.2995 - val_accuracy: 0.9227\n",
            "Epoch 631/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.2735 - val_accuracy: 0.9278\n",
            "Epoch 632/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 0.2570 - val_accuracy: 0.9324\n",
            "Epoch 633/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.2739 - val_accuracy: 0.9250\n",
            "Epoch 634/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.2760 - val_accuracy: 0.9273\n",
            "Epoch 635/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0511 - accuracy: 0.9830 - val_loss: 0.2720 - val_accuracy: 0.9301\n",
            "Epoch 636/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0547 - accuracy: 0.9809 - val_loss: 0.2676 - val_accuracy: 0.9301\n",
            "Epoch 637/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0528 - accuracy: 0.9805 - val_loss: 0.2859 - val_accuracy: 0.9215\n",
            "Epoch 638/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0562 - accuracy: 0.9815 - val_loss: 0.2749 - val_accuracy: 0.9284\n",
            "Epoch 639/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0524 - accuracy: 0.9828 - val_loss: 0.2745 - val_accuracy: 0.9307\n",
            "Epoch 640/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 0.2750 - val_accuracy: 0.9238\n",
            "Epoch 641/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0543 - accuracy: 0.9832 - val_loss: 0.2707 - val_accuracy: 0.9267\n",
            "Epoch 642/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.2748 - val_accuracy: 0.9290\n",
            "Epoch 643/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.2803 - val_accuracy: 0.9290\n",
            "Epoch 644/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0543 - accuracy: 0.9801 - val_loss: 0.2845 - val_accuracy: 0.9255\n",
            "Epoch 645/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0425 - accuracy: 0.9847 - val_loss: 0.2794 - val_accuracy: 0.9233\n",
            "Epoch 646/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0519 - accuracy: 0.9824 - val_loss: 0.2711 - val_accuracy: 0.9261\n",
            "Epoch 647/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0477 - accuracy: 0.9855 - val_loss: 0.2836 - val_accuracy: 0.9278\n",
            "Epoch 648/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.2630 - val_accuracy: 0.9313\n",
            "Epoch 649/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0579 - accuracy: 0.9826 - val_loss: 0.2750 - val_accuracy: 0.9273\n",
            "Epoch 650/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0513 - accuracy: 0.9821 - val_loss: 0.2677 - val_accuracy: 0.9278\n",
            "Epoch 651/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.2579 - val_accuracy: 0.9336\n",
            "Epoch 652/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0445 - accuracy: 0.9843 - val_loss: 0.2708 - val_accuracy: 0.9261\n",
            "Epoch 653/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0516 - accuracy: 0.9822 - val_loss: 0.2682 - val_accuracy: 0.9284\n",
            "Epoch 654/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.2592 - val_accuracy: 0.9284\n",
            "Epoch 655/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9843 - val_loss: 0.2785 - val_accuracy: 0.9284\n",
            "Epoch 656/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.2900 - val_accuracy: 0.9307\n",
            "Epoch 657/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.2636 - val_accuracy: 0.9313\n",
            "Epoch 658/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.2666 - val_accuracy: 0.9290\n",
            "Epoch 659/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0448 - accuracy: 0.9836 - val_loss: 0.2701 - val_accuracy: 0.9233\n",
            "Epoch 660/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.2793 - val_accuracy: 0.9284\n",
            "Epoch 661/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0515 - accuracy: 0.9845 - val_loss: 0.2577 - val_accuracy: 0.9290\n",
            "Epoch 662/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.2708 - val_accuracy: 0.9313\n",
            "Epoch 663/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0457 - accuracy: 0.9849 - val_loss: 0.2940 - val_accuracy: 0.9284\n",
            "Epoch 664/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0498 - accuracy: 0.9828 - val_loss: 0.2633 - val_accuracy: 0.9290\n",
            "Epoch 665/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0512 - accuracy: 0.9830 - val_loss: 0.2855 - val_accuracy: 0.9296\n",
            "Epoch 666/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0479 - accuracy: 0.9822 - val_loss: 0.2854 - val_accuracy: 0.9250\n",
            "Epoch 667/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.2751 - val_accuracy: 0.9261\n",
            "Epoch 668/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.2910 - val_accuracy: 0.9244\n",
            "Epoch 669/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0471 - accuracy: 0.9828 - val_loss: 0.2777 - val_accuracy: 0.9284\n",
            "Epoch 670/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 0.3039 - val_accuracy: 0.9267\n",
            "Epoch 671/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.2772 - val_accuracy: 0.9255\n",
            "Epoch 672/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.2773 - val_accuracy: 0.9267\n",
            "Epoch 673/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.2861 - val_accuracy: 0.9301\n",
            "Epoch 674/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9838 - val_loss: 0.2719 - val_accuracy: 0.9313\n",
            "Epoch 675/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 0.2810 - val_accuracy: 0.9250\n",
            "Epoch 676/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 0.2799 - val_accuracy: 0.9290\n",
            "Epoch 677/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 0.2985 - val_accuracy: 0.9221\n",
            "Epoch 678/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.2877 - val_accuracy: 0.9250\n",
            "Epoch 679/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9822 - val_loss: 0.2969 - val_accuracy: 0.9221\n",
            "Epoch 680/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 0.2858 - val_accuracy: 0.9296\n",
            "Epoch 681/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.2970 - val_accuracy: 0.9255\n",
            "Epoch 682/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0449 - accuracy: 0.9845 - val_loss: 0.2820 - val_accuracy: 0.9301\n",
            "Epoch 683/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.2755 - val_accuracy: 0.9273\n",
            "Epoch 684/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.2778 - val_accuracy: 0.9290\n",
            "Epoch 685/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.3139 - val_accuracy: 0.9233\n",
            "Epoch 686/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9851 - val_loss: 0.2643 - val_accuracy: 0.9330\n",
            "Epoch 687/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.2874 - val_accuracy: 0.9278\n",
            "Epoch 688/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.3076 - val_accuracy: 0.9221\n",
            "Epoch 689/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9849 - val_loss: 0.2976 - val_accuracy: 0.9221\n",
            "Epoch 690/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.2762 - val_accuracy: 0.9318\n",
            "Epoch 691/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0462 - accuracy: 0.9838 - val_loss: 0.2802 - val_accuracy: 0.9284\n",
            "Epoch 692/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0417 - accuracy: 0.9859 - val_loss: 0.2875 - val_accuracy: 0.9267\n",
            "Epoch 693/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0460 - accuracy: 0.9836 - val_loss: 0.2737 - val_accuracy: 0.9273\n",
            "Epoch 694/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.2904 - val_accuracy: 0.9198\n",
            "Epoch 695/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 0.2695 - val_accuracy: 0.9318\n",
            "Epoch 696/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.3056 - val_accuracy: 0.9227\n",
            "Epoch 697/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0455 - accuracy: 0.9870 - val_loss: 0.3074 - val_accuracy: 0.9301\n",
            "Epoch 698/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.2997 - val_accuracy: 0.9215\n",
            "Epoch 699/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0482 - accuracy: 0.9843 - val_loss: 0.2949 - val_accuracy: 0.9198\n",
            "Epoch 700/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0466 - accuracy: 0.9832 - val_loss: 0.2955 - val_accuracy: 0.9324\n",
            "Epoch 701/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 0.3004 - val_accuracy: 0.9221\n",
            "Epoch 702/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.2815 - val_accuracy: 0.9278\n",
            "Epoch 703/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.2928 - val_accuracy: 0.9255\n",
            "Epoch 704/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 0.2998 - val_accuracy: 0.9181\n",
            "Epoch 705/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.2916 - val_accuracy: 0.9210\n",
            "Epoch 706/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.2801 - val_accuracy: 0.9273\n",
            "Epoch 707/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.2858 - val_accuracy: 0.9307\n",
            "Epoch 708/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.2733 - val_accuracy: 0.9261\n",
            "Epoch 709/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0446 - accuracy: 0.9834 - val_loss: 0.2965 - val_accuracy: 0.9221\n",
            "Epoch 710/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9834 - val_loss: 0.2867 - val_accuracy: 0.9278\n",
            "Epoch 711/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.2725 - val_accuracy: 0.9284\n",
            "Epoch 712/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.2791 - val_accuracy: 0.9290\n",
            "Epoch 713/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.2789 - val_accuracy: 0.9313\n",
            "Epoch 714/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.2871 - val_accuracy: 0.9233\n",
            "Epoch 715/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 0.3040 - val_accuracy: 0.9244\n",
            "Epoch 716/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9836 - val_loss: 0.2735 - val_accuracy: 0.9313\n",
            "Epoch 717/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.2897 - val_accuracy: 0.9261\n",
            "Epoch 718/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0400 - accuracy: 0.9857 - val_loss: 0.2635 - val_accuracy: 0.9307\n",
            "Epoch 719/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.2824 - val_accuracy: 0.9278\n",
            "Epoch 720/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.2946 - val_accuracy: 0.9233\n",
            "Epoch 721/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9851 - val_loss: 0.2955 - val_accuracy: 0.9255\n",
            "Epoch 722/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0445 - accuracy: 0.9849 - val_loss: 0.2883 - val_accuracy: 0.9273\n",
            "Epoch 723/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 0.2666 - val_accuracy: 0.9290\n",
            "Epoch 724/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.2818 - val_accuracy: 0.9290\n",
            "Epoch 725/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.2930 - val_accuracy: 0.9273\n",
            "Epoch 726/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 0.2808 - val_accuracy: 0.9261\n",
            "Epoch 727/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.2850 - val_accuracy: 0.9261\n",
            "Epoch 728/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.2774 - val_accuracy: 0.9267\n",
            "Epoch 729/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.2721 - val_accuracy: 0.9278\n",
            "Epoch 730/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.2750 - val_accuracy: 0.9313\n",
            "Epoch 731/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0446 - accuracy: 0.9855 - val_loss: 0.3011 - val_accuracy: 0.9278\n",
            "Epoch 732/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0385 - accuracy: 0.9861 - val_loss: 0.2623 - val_accuracy: 0.9341\n",
            "Epoch 733/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 0.2722 - val_accuracy: 0.9336\n",
            "Epoch 734/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0395 - accuracy: 0.9864 - val_loss: 0.2751 - val_accuracy: 0.9353\n",
            "Epoch 735/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9889 - val_loss: 0.2806 - val_accuracy: 0.9336\n",
            "Epoch 736/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.2990 - val_accuracy: 0.9255\n",
            "Epoch 737/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0454 - accuracy: 0.9843 - val_loss: 0.2745 - val_accuracy: 0.9307\n",
            "Epoch 738/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.2765 - val_accuracy: 0.9290\n",
            "Epoch 739/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.2727 - val_accuracy: 0.9353\n",
            "Epoch 740/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.2663 - val_accuracy: 0.9290\n",
            "Epoch 741/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 0.2921 - val_accuracy: 0.9307\n",
            "Epoch 742/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.2899 - val_accuracy: 0.9273\n",
            "Epoch 743/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.2946 - val_accuracy: 0.9238\n",
            "Epoch 744/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0504 - accuracy: 0.9815 - val_loss: 0.3001 - val_accuracy: 0.9255\n",
            "Epoch 745/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.3018 - val_accuracy: 0.9250\n",
            "Epoch 746/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.2910 - val_accuracy: 0.9278\n",
            "Epoch 747/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0394 - accuracy: 0.9866 - val_loss: 0.2891 - val_accuracy: 0.9313\n",
            "Epoch 748/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.2847 - val_accuracy: 0.9341\n",
            "Epoch 749/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.2763 - val_accuracy: 0.9341\n",
            "Epoch 750/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.2814 - val_accuracy: 0.9353\n",
            "Epoch 751/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0421 - accuracy: 0.9884 - val_loss: 0.2855 - val_accuracy: 0.9284\n",
            "Epoch 752/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.2781 - val_accuracy: 0.9324\n",
            "Epoch 753/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0462 - accuracy: 0.9851 - val_loss: 0.2852 - val_accuracy: 0.9318\n",
            "Epoch 754/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 0.2761 - val_accuracy: 0.9307\n",
            "Epoch 755/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 0.2830 - val_accuracy: 0.9296\n",
            "Epoch 756/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.2831 - val_accuracy: 0.9313\n",
            "Epoch 757/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 0.2914 - val_accuracy: 0.9301\n",
            "Epoch 758/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 0.2787 - val_accuracy: 0.9301\n",
            "Epoch 759/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.3053 - val_accuracy: 0.9318\n",
            "Epoch 760/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.2865 - val_accuracy: 0.9284\n",
            "Epoch 761/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0449 - accuracy: 0.9824 - val_loss: 0.2980 - val_accuracy: 0.9255\n",
            "Epoch 762/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.2921 - val_accuracy: 0.9284\n",
            "Epoch 763/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.2916 - val_accuracy: 0.9296\n",
            "Epoch 764/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 0.2997 - val_accuracy: 0.9267\n",
            "Epoch 765/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.2798 - val_accuracy: 0.9307\n",
            "Epoch 766/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.2779 - val_accuracy: 0.9307\n",
            "Epoch 767/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9872 - val_loss: 0.2904 - val_accuracy: 0.9301\n",
            "Epoch 768/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.2850 - val_accuracy: 0.9324\n",
            "Epoch 769/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0465 - accuracy: 0.9843 - val_loss: 0.2817 - val_accuracy: 0.9347\n",
            "Epoch 770/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.2785 - val_accuracy: 0.9307\n",
            "Epoch 771/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.2727 - val_accuracy: 0.9307\n",
            "Epoch 772/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.2731 - val_accuracy: 0.9318\n",
            "Epoch 773/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.2739 - val_accuracy: 0.9313\n",
            "Epoch 774/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.2851 - val_accuracy: 0.9278\n",
            "Epoch 775/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9866 - val_loss: 0.2852 - val_accuracy: 0.9301\n",
            "Epoch 776/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.2881 - val_accuracy: 0.9273\n",
            "Epoch 777/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0437 - accuracy: 0.9851 - val_loss: 0.2667 - val_accuracy: 0.9290\n",
            "Epoch 778/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.2809 - val_accuracy: 0.9273\n",
            "Epoch 779/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 0.3086 - val_accuracy: 0.9250\n",
            "Epoch 780/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.2906 - val_accuracy: 0.9273\n",
            "Epoch 781/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.2961 - val_accuracy: 0.9301\n",
            "Epoch 782/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.2867 - val_accuracy: 0.9307\n",
            "Epoch 783/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.2882 - val_accuracy: 0.9290\n",
            "Epoch 784/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 0.2842 - val_accuracy: 0.9307\n",
            "Epoch 785/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.2772 - val_accuracy: 0.9341\n",
            "Epoch 786/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.2831 - val_accuracy: 0.9347\n",
            "Epoch 787/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 0.2687 - val_accuracy: 0.9353\n",
            "Epoch 788/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9874 - val_loss: 0.2731 - val_accuracy: 0.9364\n",
            "Epoch 789/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.2731 - val_accuracy: 0.9336\n",
            "Epoch 790/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.2798 - val_accuracy: 0.9301\n",
            "Epoch 791/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0497 - accuracy: 0.9834 - val_loss: 0.2676 - val_accuracy: 0.9381\n",
            "Epoch 792/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.2707 - val_accuracy: 0.9347\n",
            "Epoch 793/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.3001 - val_accuracy: 0.9347\n",
            "Epoch 794/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.2916 - val_accuracy: 0.9336\n",
            "Epoch 795/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.2790 - val_accuracy: 0.9313\n",
            "Epoch 796/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.2754 - val_accuracy: 0.9324\n",
            "Epoch 797/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0390 - accuracy: 0.9863 - val_loss: 0.2729 - val_accuracy: 0.9347\n",
            "Epoch 798/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.2816 - val_accuracy: 0.9290\n",
            "Epoch 799/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.2795 - val_accuracy: 0.9330\n",
            "Epoch 800/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.2963 - val_accuracy: 0.9273\n",
            "Epoch 801/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0394 - accuracy: 0.9849 - val_loss: 0.2644 - val_accuracy: 0.9347\n",
            "Epoch 802/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0385 - accuracy: 0.9866 - val_loss: 0.2845 - val_accuracy: 0.9301\n",
            "Epoch 803/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0366 - accuracy: 0.9906 - val_loss: 0.2938 - val_accuracy: 0.9278\n",
            "Epoch 804/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.3063 - val_accuracy: 0.9296\n",
            "Epoch 805/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.2854 - val_accuracy: 0.9273\n",
            "Epoch 806/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0437 - accuracy: 0.9851 - val_loss: 0.3081 - val_accuracy: 0.9273\n",
            "Epoch 807/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.2787 - val_accuracy: 0.9324\n",
            "Epoch 808/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9859 - val_loss: 0.2883 - val_accuracy: 0.9278\n",
            "Epoch 809/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.3042 - val_accuracy: 0.9301\n",
            "Epoch 810/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.2704 - val_accuracy: 0.9341\n",
            "Epoch 811/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.2773 - val_accuracy: 0.9336\n",
            "Epoch 812/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0394 - accuracy: 0.9889 - val_loss: 0.2729 - val_accuracy: 0.9336\n",
            "Epoch 813/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.2920 - val_accuracy: 0.9336\n",
            "Epoch 814/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 0.2815 - val_accuracy: 0.9336\n",
            "Epoch 815/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.2790 - val_accuracy: 0.9330\n",
            "Epoch 816/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.2941 - val_accuracy: 0.9301\n",
            "Epoch 817/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0395 - accuracy: 0.9863 - val_loss: 0.3025 - val_accuracy: 0.9284\n",
            "Epoch 818/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0381 - accuracy: 0.9857 - val_loss: 0.2965 - val_accuracy: 0.9284\n",
            "Epoch 819/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.2858 - val_accuracy: 0.9313\n",
            "Epoch 820/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 0.2851 - val_accuracy: 0.9301\n",
            "Epoch 821/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.2836 - val_accuracy: 0.9278\n",
            "Epoch 822/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9872 - val_loss: 0.2724 - val_accuracy: 0.9290\n",
            "Epoch 823/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.2747 - val_accuracy: 0.9318\n",
            "Epoch 824/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.2815 - val_accuracy: 0.9318\n",
            "Epoch 825/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0331 - accuracy: 0.9880 - val_loss: 0.2901 - val_accuracy: 0.9336\n",
            "Epoch 826/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0400 - accuracy: 0.9853 - val_loss: 0.2689 - val_accuracy: 0.9336\n",
            "Epoch 827/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 0.2925 - val_accuracy: 0.9290\n",
            "Epoch 828/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9864 - val_loss: 0.2897 - val_accuracy: 0.9267\n",
            "Epoch 829/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.2821 - val_accuracy: 0.9284\n",
            "Epoch 830/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.2880 - val_accuracy: 0.9296\n",
            "Epoch 831/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.2817 - val_accuracy: 0.9353\n",
            "Epoch 832/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 0.2739 - val_accuracy: 0.9318\n",
            "Epoch 833/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.2884 - val_accuracy: 0.9301\n",
            "Epoch 834/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9912 - val_loss: 0.2883 - val_accuracy: 0.9313\n",
            "Epoch 835/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.3088 - val_accuracy: 0.9296\n",
            "Epoch 836/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.2906 - val_accuracy: 0.9324\n",
            "Epoch 837/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0388 - accuracy: 0.9882 - val_loss: 0.2866 - val_accuracy: 0.9336\n",
            "Epoch 838/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.3083 - val_accuracy: 0.9284\n",
            "Epoch 839/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.2844 - val_accuracy: 0.9296\n",
            "Epoch 840/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0436 - accuracy: 0.9849 - val_loss: 0.3182 - val_accuracy: 0.9198\n",
            "Epoch 841/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.2969 - val_accuracy: 0.9261\n",
            "Epoch 842/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 0.2949 - val_accuracy: 0.9273\n",
            "Epoch 843/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9868 - val_loss: 0.2805 - val_accuracy: 0.9301\n",
            "Epoch 844/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0367 - accuracy: 0.9878 - val_loss: 0.2735 - val_accuracy: 0.9318\n",
            "Epoch 845/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 0.2795 - val_accuracy: 0.9301\n",
            "Epoch 846/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.2786 - val_accuracy: 0.9313\n",
            "Epoch 847/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 0.2845 - val_accuracy: 0.9290\n",
            "Epoch 848/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.2713 - val_accuracy: 0.9336\n",
            "Epoch 849/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 0.2920 - val_accuracy: 0.9307\n",
            "Epoch 850/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.2881 - val_accuracy: 0.9301\n",
            "Epoch 851/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.3106 - val_accuracy: 0.9301\n",
            "Epoch 852/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.2783 - val_accuracy: 0.9278\n",
            "Epoch 853/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 0.2760 - val_accuracy: 0.9324\n",
            "Epoch 854/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0347 - accuracy: 0.9868 - val_loss: 0.2769 - val_accuracy: 0.9307\n",
            "Epoch 855/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 0.2993 - val_accuracy: 0.9250\n",
            "Epoch 856/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0382 - accuracy: 0.9868 - val_loss: 0.2702 - val_accuracy: 0.9353\n",
            "Epoch 857/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.2866 - val_accuracy: 0.9278\n",
            "Epoch 858/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 0.2900 - val_accuracy: 0.9267\n",
            "Epoch 859/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.2817 - val_accuracy: 0.9290\n",
            "Epoch 860/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.2917 - val_accuracy: 0.9301\n",
            "Epoch 861/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9855 - val_loss: 0.2937 - val_accuracy: 0.9336\n",
            "Epoch 862/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.2929 - val_accuracy: 0.9284\n",
            "Epoch 863/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 0.3123 - val_accuracy: 0.9278\n",
            "Epoch 864/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.3062 - val_accuracy: 0.9261\n",
            "Epoch 865/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9899 - val_loss: 0.2982 - val_accuracy: 0.9301\n",
            "Epoch 866/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0361 - accuracy: 0.9868 - val_loss: 0.2734 - val_accuracy: 0.9318\n",
            "Epoch 867/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.2928 - val_accuracy: 0.9261\n",
            "Epoch 868/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9872 - val_loss: 0.2811 - val_accuracy: 0.9324\n",
            "Epoch 869/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.2960 - val_accuracy: 0.9267\n",
            "Epoch 870/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.2857 - val_accuracy: 0.9267\n",
            "Epoch 871/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0361 - accuracy: 0.9874 - val_loss: 0.2941 - val_accuracy: 0.9296\n",
            "Epoch 872/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.2754 - val_accuracy: 0.9278\n",
            "Epoch 873/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.2877 - val_accuracy: 0.9313\n",
            "Epoch 874/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.2905 - val_accuracy: 0.9301\n",
            "Epoch 875/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.2865 - val_accuracy: 0.9296\n",
            "Epoch 876/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 0.2785 - val_accuracy: 0.9307\n",
            "Epoch 877/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.2986 - val_accuracy: 0.9307\n",
            "Epoch 878/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0377 - accuracy: 0.9891 - val_loss: 0.3229 - val_accuracy: 0.9210\n",
            "Epoch 879/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.2898 - val_accuracy: 0.9307\n",
            "Epoch 880/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.2844 - val_accuracy: 0.9307\n",
            "Epoch 881/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 0.2721 - val_accuracy: 0.9318\n",
            "Epoch 882/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.2736 - val_accuracy: 0.9359\n",
            "Epoch 883/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.2883 - val_accuracy: 0.9376\n",
            "Epoch 884/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.2846 - val_accuracy: 0.9301\n",
            "Epoch 885/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.2962 - val_accuracy: 0.9324\n",
            "Epoch 886/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.2848 - val_accuracy: 0.9313\n",
            "Epoch 887/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 0.2679 - val_accuracy: 0.9353\n",
            "Epoch 888/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.2986 - val_accuracy: 0.9313\n",
            "Epoch 889/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.2877 - val_accuracy: 0.9267\n",
            "Epoch 890/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.2853 - val_accuracy: 0.9318\n",
            "Epoch 891/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0406 - accuracy: 0.9855 - val_loss: 0.2772 - val_accuracy: 0.9359\n",
            "Epoch 892/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.2722 - val_accuracy: 0.9324\n",
            "Epoch 893/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.2619 - val_accuracy: 0.9376\n",
            "Epoch 894/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.2616 - val_accuracy: 0.9341\n",
            "Epoch 895/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.2724 - val_accuracy: 0.9324\n",
            "Epoch 896/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 0.2816 - val_accuracy: 0.9336\n",
            "Epoch 897/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.2720 - val_accuracy: 0.9307\n",
            "Epoch 898/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.2824 - val_accuracy: 0.9341\n",
            "Epoch 899/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0388 - accuracy: 0.9849 - val_loss: 0.2961 - val_accuracy: 0.9261\n",
            "Epoch 900/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.2704 - val_accuracy: 0.9341\n",
            "Epoch 901/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.2863 - val_accuracy: 0.9313\n",
            "Epoch 902/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0349 - accuracy: 0.9878 - val_loss: 0.2736 - val_accuracy: 0.9359\n",
            "Epoch 903/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.2876 - val_accuracy: 0.9318\n",
            "Epoch 904/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.2933 - val_accuracy: 0.9336\n",
            "Epoch 905/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 0.2760 - val_accuracy: 0.9353\n",
            "Epoch 906/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 0.2706 - val_accuracy: 0.9347\n",
            "Epoch 907/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0336 - accuracy: 0.9910 - val_loss: 0.2721 - val_accuracy: 0.9330\n",
            "Epoch 908/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.2989 - val_accuracy: 0.9255\n",
            "Epoch 909/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.3044 - val_accuracy: 0.9301\n",
            "Epoch 910/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.2882 - val_accuracy: 0.9336\n",
            "Epoch 911/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 0.3028 - val_accuracy: 0.9273\n",
            "Epoch 912/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.2970 - val_accuracy: 0.9301\n",
            "Epoch 913/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.2756 - val_accuracy: 0.9318\n",
            "Epoch 914/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9893 - val_loss: 0.2839 - val_accuracy: 0.9364\n",
            "Epoch 915/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0339 - accuracy: 0.9870 - val_loss: 0.2817 - val_accuracy: 0.9301\n",
            "Epoch 916/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.2910 - val_accuracy: 0.9313\n",
            "Epoch 917/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 0.2874 - val_accuracy: 0.9255\n",
            "Epoch 918/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.2920 - val_accuracy: 0.9347\n",
            "Epoch 919/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.2756 - val_accuracy: 0.9347\n",
            "Epoch 920/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.2898 - val_accuracy: 0.9290\n",
            "Epoch 921/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.3040 - val_accuracy: 0.9284\n",
            "Epoch 922/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.2798 - val_accuracy: 0.9341\n",
            "Epoch 923/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.2951 - val_accuracy: 0.9296\n",
            "Epoch 924/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.3050 - val_accuracy: 0.9341\n",
            "Epoch 925/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 0.3020 - val_accuracy: 0.9341\n",
            "Epoch 926/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.2727 - val_accuracy: 0.9353\n",
            "Epoch 927/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.2776 - val_accuracy: 0.9341\n",
            "Epoch 928/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.2857 - val_accuracy: 0.9353\n",
            "Epoch 929/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9880 - val_loss: 0.3020 - val_accuracy: 0.9307\n",
            "Epoch 930/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.2780 - val_accuracy: 0.9330\n",
            "Epoch 931/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.2771 - val_accuracy: 0.9353\n",
            "Epoch 932/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9897 - val_loss: 0.2945 - val_accuracy: 0.9318\n",
            "Epoch 933/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.2731 - val_accuracy: 0.9347\n",
            "Epoch 934/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9870 - val_loss: 0.2840 - val_accuracy: 0.9347\n",
            "Epoch 935/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.2880 - val_accuracy: 0.9318\n",
            "Epoch 936/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.2961 - val_accuracy: 0.9307\n",
            "Epoch 937/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0367 - accuracy: 0.9872 - val_loss: 0.2761 - val_accuracy: 0.9381\n",
            "Epoch 938/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.2699 - val_accuracy: 0.9341\n",
            "Epoch 939/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.2774 - val_accuracy: 0.9318\n",
            "Epoch 940/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.2862 - val_accuracy: 0.9290\n",
            "Epoch 941/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0347 - accuracy: 0.9868 - val_loss: 0.2756 - val_accuracy: 0.9318\n",
            "Epoch 942/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.2654 - val_accuracy: 0.9341\n",
            "Epoch 943/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.2785 - val_accuracy: 0.9359\n",
            "Epoch 944/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.2863 - val_accuracy: 0.9313\n",
            "Epoch 945/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.3233 - val_accuracy: 0.9261\n",
            "Epoch 946/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 0.2925 - val_accuracy: 0.9353\n",
            "Epoch 947/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.3066 - val_accuracy: 0.9284\n",
            "Epoch 948/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.2906 - val_accuracy: 0.9330\n",
            "Epoch 949/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.2878 - val_accuracy: 0.9359\n",
            "Epoch 950/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.2881 - val_accuracy: 0.9318\n",
            "Epoch 951/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.2787 - val_accuracy: 0.9381\n",
            "Epoch 952/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0398 - accuracy: 0.9868 - val_loss: 0.2913 - val_accuracy: 0.9364\n",
            "Epoch 953/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0335 - accuracy: 0.9910 - val_loss: 0.2887 - val_accuracy: 0.9341\n",
            "Epoch 954/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 0.2811 - val_accuracy: 0.9336\n",
            "Epoch 955/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.2863 - val_accuracy: 0.9336\n",
            "Epoch 956/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.2800 - val_accuracy: 0.9364\n",
            "Epoch 957/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.2763 - val_accuracy: 0.9353\n",
            "Epoch 958/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.2789 - val_accuracy: 0.9353\n",
            "Epoch 959/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.2905 - val_accuracy: 0.9296\n",
            "Epoch 960/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 0.2943 - val_accuracy: 0.9290\n",
            "Epoch 961/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9901 - val_loss: 0.2918 - val_accuracy: 0.9347\n",
            "Epoch 962/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.3143 - val_accuracy: 0.9244\n",
            "Epoch 963/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.3022 - val_accuracy: 0.9307\n",
            "Epoch 964/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.2729 - val_accuracy: 0.9336\n",
            "Epoch 965/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.2835 - val_accuracy: 0.9318\n",
            "Epoch 966/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 0.2773 - val_accuracy: 0.9347\n",
            "Epoch 967/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.3060 - val_accuracy: 0.9273\n",
            "Epoch 968/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9878 - val_loss: 0.2951 - val_accuracy: 0.9324\n",
            "Epoch 969/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.3010 - val_accuracy: 0.9330\n",
            "Epoch 970/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.2938 - val_accuracy: 0.9267\n",
            "Epoch 971/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.3114 - val_accuracy: 0.9261\n",
            "Epoch 972/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.2918 - val_accuracy: 0.9278\n",
            "Epoch 973/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.3011 - val_accuracy: 0.9255\n",
            "Epoch 974/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.2875 - val_accuracy: 0.9307\n",
            "Epoch 975/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.3133 - val_accuracy: 0.9267\n",
            "Epoch 976/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.3109 - val_accuracy: 0.9347\n",
            "Epoch 977/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.2917 - val_accuracy: 0.9336\n",
            "Epoch 978/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.3153 - val_accuracy: 0.9313\n",
            "Epoch 979/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.3182 - val_accuracy: 0.9313\n",
            "Epoch 980/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 0.2956 - val_accuracy: 0.9347\n",
            "Epoch 981/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 0.3199 - val_accuracy: 0.9296\n",
            "Epoch 982/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.2891 - val_accuracy: 0.9307\n",
            "Epoch 983/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.2765 - val_accuracy: 0.9313\n",
            "Epoch 984/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.2946 - val_accuracy: 0.9318\n",
            "Epoch 985/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0365 - accuracy: 0.9891 - val_loss: 0.2955 - val_accuracy: 0.9290\n",
            "Epoch 986/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9868 - val_loss: 0.2912 - val_accuracy: 0.9347\n",
            "Epoch 987/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0299 - accuracy: 0.9887 - val_loss: 0.2907 - val_accuracy: 0.9296\n",
            "Epoch 988/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 0.2840 - val_accuracy: 0.9318\n",
            "Epoch 989/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.2921 - val_accuracy: 0.9330\n",
            "Epoch 990/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.2853 - val_accuracy: 0.9307\n",
            "Epoch 991/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.2809 - val_accuracy: 0.9301\n",
            "Epoch 992/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.2690 - val_accuracy: 0.9359\n",
            "Epoch 993/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.2888 - val_accuracy: 0.9353\n",
            "Epoch 994/1000\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.3082 - val_accuracy: 0.9296\n",
            "Epoch 995/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.2861 - val_accuracy: 0.9324\n",
            "Epoch 996/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0297 - accuracy: 0.9891 - val_loss: 0.2896 - val_accuracy: 0.9336\n",
            "Epoch 997/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.2946 - val_accuracy: 0.9307\n",
            "Epoch 998/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.2872 - val_accuracy: 0.9307\n",
            "Epoch 999/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.3083 - val_accuracy: 0.9307\n",
            "Epoch 1000/1000\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.3005 - val_accuracy: 0.9347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 7))\n",
        "\n",
        "plt.plot([i for i in range(1, n_epochs + 1)], hist.history['loss'], color = 'blue', label = 'train')\n",
        "plt.plot([i for i in range(1, n_epochs + 1)], hist.history['val_loss'], color = 'red', label = 'val')\n",
        "\n",
        "plt.xlabel('Epochs', fontsize = 17)\n",
        "plt.ylabel('Loss', fontsize = 17)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "yIP7P825c3gT",
        "outputId": "f3457783-0d5b-4dc1-bec6-32676da3a1f4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 7))\n",
        "\n",
        "plt.plot([i for i in range(1, n_epochs + 1)], hist.history['accuracy'], color = 'blue', label = 'train')\n",
        "plt.plot([i for i in range(1, n_epochs + 1)], hist.history['val_accuracy'], color = 'red', label = 'val')\n",
        "plt.plot([i for i in range(1, n_epochs + 1)], [0.9 for i in range(1, n_epochs + 1)], color = 'orange', label = 'line')\n",
        "plt.plot([i for i in range(1, n_epochs + 1)], [0.95 for i in range(1, n_epochs + 1)], color = 'orange', label = 'line')\n",
        "\n",
        "plt.xlabel('Epochs', fontsize = 17)\n",
        "plt.ylabel('Accuracy', fontsize = 17)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "hEAvDnz_ka1E",
        "outputId": "77450c6f-2681-4b3d-8a7c-4f7f918adf87"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Save the model"
      ],
      "metadata": {
        "id": "LmHyAr4-ngD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('drive/MyDrive/Profesional_Academico/Github_Personal/ML_AI_Contents/09.Deep_Learning/73.Audio_NN_Scratch/model/model.weights.h5')"
      ],
      "metadata": {
        "id": "QBrpLov2npsZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End of execution"
      ],
      "metadata": {
        "id": "xq8G7JCqnn5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end = time.time()\n",
        "\n",
        "delta = (end - start)\n",
        "\n",
        "hours = int(delta/3_600)\n",
        "mins = int((delta - hours*3_600)/60)\n",
        "secs = int(delta - hours*3_600 - mins*60)\n",
        "\n",
        "print(f'Hours: {hours}, Minutes: {mins}, Seconds: {secs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF06LqSKno0q",
        "outputId": "6d3e2301-c48a-4748-a73c-03bf182eec1f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hours: 0, Minutes: 10, Seconds: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F4VZZBP8nqoA"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}