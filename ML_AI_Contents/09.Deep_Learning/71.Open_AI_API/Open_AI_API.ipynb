{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Open AI API"
      ],
      "metadata": {
        "id": "L0QxOuOzbp83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xMTMP4VAZB_I"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import huggingface_hub\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "QHovvgBeZMlq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGING_FACE_TOKEN = userdata.get('HUGGING_FACE_TOKEN')"
      ],
      "metadata": {
        "id": "052iVs0QZYYs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_token = HUGGING_FACE_TOKEN"
      ],
      "metadata": {
        "id": "nymustcGZWQ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url = \"https://api-inference.huggingface.co/v1/\",\n",
        "    api_key = HUGGING_FACE_TOKEN,\n",
        ")"
      ],
      "metadata": {
        "id": "sYaltEcCZPpL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\""
      ],
      "metadata": {
        "id": "vy1nynWQbUff"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model = model_id,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful an honest programming assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Is Rust better than Python?\"},\n",
        "    ],\n",
        "    stream = True,\n",
        "    max_tokens = 500\n",
        ")"
      ],
      "metadata": {
        "id": "5VBZH2MNZmKn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = \"\"\n",
        "\n",
        "for message in chat_completion:\n",
        "    response = response + message.choices[0].delta.content"
      ],
      "metadata": {
        "id": "bzc8vkzycEpU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for message in chat_completion:\n",
        "    print(message.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "id": "GxTfr2RCZ4mA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = response.split(\"\\n\")"
      ],
      "metadata": {
        "id": "-5fW2nwAb6aC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_response = [r for r in response if r != '']"
      ],
      "metadata": {
        "id": "22osFuTwcaUk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in new_response:\n",
        "  print(r)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCxUoEw3cV0x",
        "outputId": "8e112894-bdb2-4b52-8954-18f90110b901"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's not appropriate to say that one programming language is better than another, as it ultimately depends on the specific needs and preferences of the user. Rust and Python are both powerful programming languages, and they each have their own unique strengths and weaknesses.\n",
            "\n",
            "\n",
            "Rust is a systems programming language that is known for its high performance, safety, and concurrency features. It is often used for developing low-level operating systems, system libraries, and other systems-level software. Rust's ownership and borrowing model allows for memory safety, and its use of the C-like syntax allows for high-performance code. Rust is also strong in concurrency with its support for multi-threading and the concept of \"poisoning a system\"\n",
            "\n",
            "\n",
            "Python, on the other hand, is a general-purpose programming language that is commonly used for scripting, data science, and machine learning. It is known for its simplicity, readability, and ease of use. Python's dynamic typing and vast library ecosystem make it a great choice for rapid prototyping and developing applications. Furthermore, Python is also used for web development, with popular frameworks such as Django and Flask.\n",
            "\n",
            "\n",
            "In summary, both Rust and Python are strong programming languages, and the choice of which one to use ultimately depends on the specific needs and preferences of the user. While Rust may be better suited for building system-level software, Python may be more appropriate for general-purpose programming and scripting.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aB0j_BHWcroa"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}