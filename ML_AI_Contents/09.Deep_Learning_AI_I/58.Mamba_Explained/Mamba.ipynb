{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was executed in Google Colab using A100-GPU"
      ],
      "metadata": {
        "id": "JL6kOvMBXVhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start of execution"
      ],
      "metadata": {
        "id": "9gFJkmxcXp3s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RbREDzOQW57E"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()"
      ],
      "metadata": {
        "id": "uCRcPWITXtqu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setting the environment"
      ],
      "metadata": {
        "id": "IpA0eEPeXwvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets==2.20.0"
      ],
      "metadata": {
        "id": "3Oj0MqyCXvhw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import libraries"
      ],
      "metadata": {
        "id": "JjlY0hcKX44X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "5ipx1_9wX2WM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "QCOCX6LvX8mB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load model"
      ],
      "metadata": {
        "id": "RNvhYB2FYW5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")"
      ],
      "metadata": {
        "id": "QjlLaJpokS_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4e0e66-1460-4008-f915-6c8ca0fd1696"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0O3ymT5b_et",
        "outputId": "a4676e5f-6d2e-403e-ff0f-bdfd56cf7f92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Inference"
      ],
      "metadata": {
        "id": "qknDViMBcHYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hey how are you doing?\""
      ],
      "metadata": {
        "id": "5f9YGBkFcKg7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(text, return_tensors= \"pt\")[\"input_ids\"]"
      ],
      "metadata": {
        "id": "KEXfOP-scJkB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.generate(input_ids, max_new_tokens=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFFZXzrIcJiD",
        "outputId": "35aa5807-0501-4a83-838d-895505f9f24f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.batch_decode(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RvbCV9bcJfy",
        "outputId": "11b7130c-f86e-400c-a664-0b650b6cef5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Hey how are you doing?\\n\\nI'm so glad you're here.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End of execution"
      ],
      "metadata": {
        "id": "dRjm0tsMcV0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end = time.time()\n",
        "\n",
        "delta = (end - start)\n",
        "\n",
        "hours = int(delta/3_600)\n",
        "mins = int((delta - hours*3_600)/60)\n",
        "secs = int(delta - hours*3_600 - mins*60)\n",
        "\n",
        "print(f'Hours: {hours}, Minutes: {mins}, Seconds: {secs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdJFJQ10a9M8",
        "outputId": "515ba6ca-a8b7-4978-aa72-02eff38968e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hours: 0, Minutes: 0, Seconds: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVpUEFGVcbd6"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}